{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P9Syv30TzKYv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pRXFjO2czKZA",
    "outputId": "1175dbd3-fe0b-485c-f314-52b0b70840a3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing Packages \n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "%matplotlib inline\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Input,Dense,Flatten,Dropout,merge,Reshape,Conv2D,MaxPooling2D,UpSampling2D,Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model,Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import cv2 \n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iDE6BlEhTBNg",
    "outputId": "7e369c56-0e0e-4fa3-daf3-ad4edaeae296"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "'''Mount this to your google drive location where data exists'''\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ICm_kYPazKZI"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import glob\n",
    "import os\n",
    "#os.chdir('C:\\\\Users\\\\kaviy\\\\Downloads\\\\1512427\\\\brainTumorDataPublic_1-766')\n",
    "#path_dir = os.fsencode('content/drive/My Drive/ML_proj/data')\n",
    "#print(path_dir)\n",
    "'''Uncomment the line below and please insert the directory where the numpy file exists'''\n",
    "#os.chdir('/content/drive/')\n",
    "\n",
    "'''Uncomment these following lines to load numpy files of images directly if working on google drive'''\n",
    "# X = np.load('X.npy')\n",
    "# Y = np.load('Y.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SNxL0I1NXXZA",
    "outputId": "46cc9c34-d2ab-4d93-ffd0-14b8f37dc7b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3049, 64, 64)"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dtBEkUKbzKZN"
   },
   "outputs": [],
   "source": [
    "'''Use this if running on local machine'''\n",
    "\n",
    "import glob\n",
    "import os\n",
    "'''Insert the directory where images exist (.mat data)'''\n",
    "#os.chdir('')\n",
    "files=glob.glob('*.mat')\n",
    "X=[]\n",
    "Y=[]\n",
    "data=[]\n",
    "count=0\n",
    "#a = 1\n",
    "for file in files:\n",
    "  #print(file)\n",
    "    with h5py.File(file,'r') as f:\n",
    "        variables=f.items()\n",
    "        for var in variables:\n",
    "            name= var[0]\n",
    "            data=var[1]\n",
    "            if (np.array(data['tumorMask']).shape[1] == 256):\n",
    "                count+=1\n",
    "                print(count)\n",
    "            else:\n",
    "                d=data['image']\n",
    "                X.append(cv2.resize(np.array(d),dsize=(64,64),interpolation=cv2.INTER_AREA))\n",
    "\n",
    "                #X.append(np.array(d))\n",
    "                #X.append(np.array(data['tumorMask']))\n",
    "                Y.append(data['label'][0][0])\n",
    "\n",
    "              #a = data['label'][0][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "24a2m3kX5WHS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R8bSTk30WNN-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZKjFtTISzKZT",
    "outputId": "9b2489b8-9658-4122-d367-599cd648e06a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3049, 64, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.array(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "54pZdYNvzKZa",
    "outputId": "194e9987-ab1e-4d25-9a7d-ae1358f73470"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3049,)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.array(Y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dkHkVdFgzKZh"
   },
   "outputs": [],
   "source": [
    "# Y = np.array(Y)\n",
    "# Y=Y-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0usptK8yzKZm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MFz0jzTMzKZp"
   },
   "outputs": [],
   "source": [
    "# Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Kvz5xEjzKZu"
   },
   "outputs": [],
   "source": [
    "'''Data Preprocessing'''\n",
    "X = np.array(X).reshape(-1,64,64, 1)\n",
    "#Y=np.array(Y).reshape(-1,1,1,1)\n",
    "#Y=Y.astype('float32')\n",
    "# Y=Y/255.\n",
    "X = X.astype('float32')\n",
    "X = X / 255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fTw2dAPxzKZy",
    "outputId": "b909e7ef-8ba6-4547-e9a7-ff1e76e554e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2286, 64, 64, 1), (763, 64, 64, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Initial Split'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.25)\n",
    "#X_train.shape , X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nyEREOUIzKZ6",
    "outputId": "7c589f63-0ad9-4614-9acd-7cf5ec312e5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((763,), (2286,))"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.array(Y_test).shape , np.array(Y_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GMC2XZ8TzKZ_"
   },
   "outputs": [],
   "source": [
    "'''Scaling'''\n",
    "X_train=X_train / np.max(X_train)\n",
    "\n",
    "X_test=X_test / np.max(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5DWPnMDhzKaF"
   },
   "outputs": [],
   "source": [
    "'''Reconstruction of images using unsupervised learning'''\n",
    "train_X,valid_X,train_ground,valid_ground = train_test_split(X_train,\n",
    "                                                             X_train,\n",
    "                                                             test_size=0.25,\n",
    "                                                             random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mtedU3s3zKaL"
   },
   "outputs": [],
   "source": [
    "# Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4XYJiVGSzKaP"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 10\n",
    "inChannel = 1\n",
    "x, y = 64, 64\n",
    "input_img = Input(shape = (x, y, inChannel))\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VEotr4RnzKaX"
   },
   "outputs": [],
   "source": [
    "'''Layer structure for reconstruction'''\n",
    "def encoder(input_img):\n",
    "    #encoder\n",
    "    #input = 28 x 28 x 1 (wide and thin)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) #64 x 64 x 32\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #32 x 32 x 32 #Reduces dimesnions\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #32 x 32 x 64\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #16 x 16 x 64\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #16 x 16 x 128 (small and thick)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3) #16 x 16 x 256 (small and thick)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    return conv4\n",
    "\n",
    "def decoder(conv4):    \n",
    "    #decoder\n",
    "#     conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4) #7 x 7 x 128\n",
    "#     conv5 = BatchNormalization()(conv5)\n",
    "#     conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv5)\n",
    "#     conv5 = BatchNormalization()(conv5)\n",
    "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv4) #16 x 16 x 128\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6) #16 x 16 x 64\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    up1 = UpSampling2D((2,2))(conv7) #32 x 32 x 64 #Upsamling to get back same dimension reduced by max pooling\n",
    "    conv8 = Conv2D(32, (3, 3), activation='relu', padding='same')(up1) # 32 x 32 x 32\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    up2 = UpSampling2D((2,2))(conv8) # 64 x 64 x 32\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2) # 64 x 64 x 1\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "GpIR1No9zKah",
    "outputId": "5297965d-556f-4eea-9ea0-5ff626c8ddba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Model(input_img, decoder(encoder(input_img)))\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33704
    },
    "colab_type": "code",
    "id": "lQ9_FWiMzKaq",
    "outputId": "187316cc-751c-4650-900c-58f531a63b2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1714 samples, validate on 572 samples\n",
      "Epoch 1/1000\n",
      "1714/1714 [==============================] - 8s 4ms/step - loss: 0.0937 - val_loss: 0.1706\n",
      "Epoch 2/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0373 - val_loss: 0.2976\n",
      "Epoch 3/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0195 - val_loss: 0.7399\n",
      "Epoch 4/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0101 - val_loss: 0.6502\n",
      "Epoch 5/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0096 - val_loss: 0.1057\n",
      "Epoch 6/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0088 - val_loss: 0.1238\n",
      "Epoch 7/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 8/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 9/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0100 - val_loss: 0.0047\n",
      "Epoch 10/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0041 - val_loss: 0.0074\n",
      "Epoch 11/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0056 - val_loss: 0.0126\n",
      "Epoch 12/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0044 - val_loss: 0.0151\n",
      "Epoch 13/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0021 - val_loss: 0.0172\n",
      "Epoch 14/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0019 - val_loss: 0.0131\n",
      "Epoch 15/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0019 - val_loss: 0.0160\n",
      "Epoch 16/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0017 - val_loss: 0.0256\n",
      "Epoch 17/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0016 - val_loss: 0.0107\n",
      "Epoch 18/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0015 - val_loss: 0.0076\n",
      "Epoch 19/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0014 - val_loss: 0.0066\n",
      "Epoch 20/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 21/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 22/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0012 - val_loss: 0.0126\n",
      "Epoch 23/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0011 - val_loss: 0.0080\n",
      "Epoch 24/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 25/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 26/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 0.0010 - val_loss: 0.0021\n",
      "Epoch 27/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 9.8854e-04 - val_loss: 0.0016\n",
      "Epoch 28/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 9.3065e-04 - val_loss: 0.0012\n",
      "Epoch 29/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 9.2775e-04 - val_loss: 0.0019\n",
      "Epoch 30/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 9.1434e-04 - val_loss: 0.0020\n",
      "Epoch 31/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 8.7709e-04 - val_loss: 0.0016\n",
      "Epoch 32/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 8.7476e-04 - val_loss: 0.0011\n",
      "Epoch 33/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 8.3827e-04 - val_loss: 0.0013\n",
      "Epoch 34/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 8.1543e-04 - val_loss: 0.0015\n",
      "Epoch 35/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 8.5245e-04 - val_loss: 0.0017\n",
      "Epoch 36/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 8.1170e-04 - val_loss: 0.0022\n",
      "Epoch 37/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 7.9689e-04 - val_loss: 0.0018\n",
      "Epoch 38/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 7.7979e-04 - val_loss: 0.0015\n",
      "Epoch 39/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 7.9353e-04 - val_loss: 0.0022\n",
      "Epoch 40/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 7.5493e-04 - val_loss: 0.0016\n",
      "Epoch 41/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 7.2684e-04 - val_loss: 0.0022\n",
      "Epoch 42/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 7.5884e-04 - val_loss: 0.0022\n",
      "Epoch 43/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 7.1955e-04 - val_loss: 0.0012\n",
      "Epoch 44/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 7.3594e-04 - val_loss: 0.0014\n",
      "Epoch 45/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 7.0098e-04 - val_loss: 0.0010\n",
      "Epoch 46/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 7.1011e-04 - val_loss: 0.0013\n",
      "Epoch 47/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 6.8506e-04 - val_loss: 0.0013\n",
      "Epoch 48/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 6.9569e-04 - val_loss: 0.0010\n",
      "Epoch 49/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 6.9589e-04 - val_loss: 0.0020\n",
      "Epoch 50/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 6.8279e-04 - val_loss: 0.0012\n",
      "Epoch 51/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 6.7339e-04 - val_loss: 9.3199e-04\n",
      "Epoch 52/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 6.6437e-04 - val_loss: 6.6452e-04\n",
      "Epoch 53/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 6.3860e-04 - val_loss: 6.9483e-04\n",
      "Epoch 54/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 6.4518e-04 - val_loss: 8.5235e-04\n",
      "Epoch 55/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 6.4690e-04 - val_loss: 8.9856e-04\n",
      "Epoch 56/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 6.5526e-04 - val_loss: 0.0010\n",
      "Epoch 57/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 6.2069e-04 - val_loss: 0.0011\n",
      "Epoch 58/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 6.2790e-04 - val_loss: 0.0012\n",
      "Epoch 59/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 6.2509e-04 - val_loss: 0.0024\n",
      "Epoch 60/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 6.1276e-04 - val_loss: 0.0020\n",
      "Epoch 61/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 6.4517e-04 - val_loss: 7.7450e-04\n",
      "Epoch 62/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 6.0533e-04 - val_loss: 0.0019\n",
      "Epoch 63/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.9524e-04 - val_loss: 0.0018\n",
      "Epoch 64/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 6.1615e-04 - val_loss: 0.0013\n",
      "Epoch 65/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.9124e-04 - val_loss: 7.2440e-04\n",
      "Epoch 66/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.8256e-04 - val_loss: 0.0013\n",
      "Epoch 67/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 6.0252e-04 - val_loss: 0.0012\n",
      "Epoch 68/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.9676e-04 - val_loss: 0.0011\n",
      "Epoch 69/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.7002e-04 - val_loss: 8.3572e-04\n",
      "Epoch 70/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.8132e-04 - val_loss: 7.4981e-04\n",
      "Epoch 71/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.8005e-04 - val_loss: 5.6957e-04\n",
      "Epoch 72/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.5745e-04 - val_loss: 6.9896e-04\n",
      "Epoch 73/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.6347e-04 - val_loss: 7.8668e-04\n",
      "Epoch 74/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.6008e-04 - val_loss: 6.9008e-04\n",
      "Epoch 75/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.4721e-04 - val_loss: 5.7522e-04\n",
      "Epoch 76/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.6047e-04 - val_loss: 6.7471e-04\n",
      "Epoch 77/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.3950e-04 - val_loss: 0.0012\n",
      "Epoch 78/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.5453e-04 - val_loss: 6.8029e-04\n",
      "Epoch 79/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.4148e-04 - val_loss: 7.4280e-04\n",
      "Epoch 80/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.2672e-04 - val_loss: 9.2591e-04\n",
      "Epoch 81/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.5304e-04 - val_loss: 0.0010\n",
      "Epoch 82/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.3873e-04 - val_loss: 7.9224e-04\n",
      "Epoch 83/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.3473e-04 - val_loss: 6.8779e-04\n",
      "Epoch 84/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.3788e-04 - val_loss: 0.0015\n",
      "Epoch 85/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.6362e-04 - val_loss: 0.0012\n",
      "Epoch 86/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.1303e-04 - val_loss: 9.8147e-04\n",
      "Epoch 87/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.3669e-04 - val_loss: 0.0013\n",
      "Epoch 88/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.1393e-04 - val_loss: 6.0948e-04\n",
      "Epoch 89/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.2797e-04 - val_loss: 7.1811e-04\n",
      "Epoch 90/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.9716e-04 - val_loss: 5.7462e-04\n",
      "Epoch 91/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.3347e-04 - val_loss: 6.7086e-04\n",
      "Epoch 92/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.0764e-04 - val_loss: 5.3615e-04\n",
      "Epoch 93/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.9825e-04 - val_loss: 4.8110e-04\n",
      "Epoch 94/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.3787e-04 - val_loss: 5.9425e-04\n",
      "Epoch 95/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.1619e-04 - val_loss: 5.1666e-04\n",
      "Epoch 96/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.0709e-04 - val_loss: 5.0228e-04\n",
      "Epoch 97/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.0373e-04 - val_loss: 9.1119e-04\n",
      "Epoch 98/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.0528e-04 - val_loss: 7.3365e-04\n",
      "Epoch 99/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.0632e-04 - val_loss: 5.1471e-04\n",
      "Epoch 100/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.1386e-04 - val_loss: 5.5687e-04\n",
      "Epoch 101/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.9797e-04 - val_loss: 5.2289e-04\n",
      "Epoch 102/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.9146e-04 - val_loss: 5.3111e-04\n",
      "Epoch 103/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.9525e-04 - val_loss: 5.4093e-04\n",
      "Epoch 104/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.9961e-04 - val_loss: 5.2949e-04\n",
      "Epoch 105/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.0994e-04 - val_loss: 6.2174e-04\n",
      "Epoch 106/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.9353e-04 - val_loss: 8.6672e-04\n",
      "Epoch 107/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 5.0286e-04 - val_loss: 8.9834e-04\n",
      "Epoch 108/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.7629e-04 - val_loss: 0.0014\n",
      "Epoch 109/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.8108e-04 - val_loss: 5.6450e-04\n",
      "Epoch 110/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.7116e-04 - val_loss: 4.7053e-04\n",
      "Epoch 111/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.8321e-04 - val_loss: 5.3261e-04\n",
      "Epoch 112/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.8351e-04 - val_loss: 7.2692e-04\n",
      "Epoch 113/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.7883e-04 - val_loss: 6.0878e-04\n",
      "Epoch 114/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.6664e-04 - val_loss: 5.5555e-04\n",
      "Epoch 115/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.7350e-04 - val_loss: 0.0010\n",
      "Epoch 116/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.5951e-04 - val_loss: 8.3506e-04\n",
      "Epoch 117/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.6904e-04 - val_loss: 7.0661e-04\n",
      "Epoch 118/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.6653e-04 - val_loss: 6.8818e-04\n",
      "Epoch 119/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.6097e-04 - val_loss: 0.0012\n",
      "Epoch 120/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.6193e-04 - val_loss: 5.8970e-04\n",
      "Epoch 121/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.6549e-04 - val_loss: 5.3003e-04\n",
      "Epoch 122/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.7175e-04 - val_loss: 5.2808e-04\n",
      "Epoch 123/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.3501e-04 - val_loss: 5.3251e-04\n",
      "Epoch 124/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.6196e-04 - val_loss: 6.9157e-04\n",
      "Epoch 125/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.6568e-04 - val_loss: 8.3580e-04\n",
      "Epoch 126/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.7367e-04 - val_loss: 5.0763e-04\n",
      "Epoch 127/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.5310e-04 - val_loss: 5.1725e-04\n",
      "Epoch 128/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.5089e-04 - val_loss: 5.4661e-04\n",
      "Epoch 129/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.6303e-04 - val_loss: 4.8480e-04\n",
      "Epoch 130/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.3682e-04 - val_loss: 5.9235e-04\n",
      "Epoch 131/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.6177e-04 - val_loss: 4.9699e-04\n",
      "Epoch 132/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.5758e-04 - val_loss: 4.3644e-04\n",
      "Epoch 133/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.5000e-04 - val_loss: 4.7100e-04\n",
      "Epoch 134/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.5094e-04 - val_loss: 6.7567e-04\n",
      "Epoch 135/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.3236e-04 - val_loss: 4.7471e-04\n",
      "Epoch 136/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.4511e-04 - val_loss: 5.6842e-04\n",
      "Epoch 137/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.7129e-04 - val_loss: 9.4151e-04\n",
      "Epoch 138/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.5699e-04 - val_loss: 0.0011\n",
      "Epoch 139/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.4973e-04 - val_loss: 5.5068e-04\n",
      "Epoch 140/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.3118e-04 - val_loss: 6.3072e-04\n",
      "Epoch 141/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.5176e-04 - val_loss: 5.7484e-04\n",
      "Epoch 142/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.6446e-04 - val_loss: 8.5932e-04\n",
      "Epoch 143/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.3028e-04 - val_loss: 6.6050e-04\n",
      "Epoch 144/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.4602e-04 - val_loss: 5.1814e-04\n",
      "Epoch 145/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.3365e-04 - val_loss: 5.0563e-04\n",
      "Epoch 146/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.3127e-04 - val_loss: 6.7527e-04\n",
      "Epoch 147/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.2519e-04 - val_loss: 5.4737e-04\n",
      "Epoch 148/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.2918e-04 - val_loss: 6.2696e-04\n",
      "Epoch 149/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.3970e-04 - val_loss: 4.7949e-04\n",
      "Epoch 150/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.2447e-04 - val_loss: 6.0388e-04\n",
      "Epoch 151/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.2807e-04 - val_loss: 5.0764e-04\n",
      "Epoch 152/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.4154e-04 - val_loss: 4.9994e-04\n",
      "Epoch 153/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.2680e-04 - val_loss: 5.4440e-04\n",
      "Epoch 154/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.2866e-04 - val_loss: 5.3813e-04\n",
      "Epoch 155/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.4001e-04 - val_loss: 5.4418e-04\n",
      "Epoch 156/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.4411e-04 - val_loss: 5.7771e-04\n",
      "Epoch 157/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.3494e-04 - val_loss: 4.6563e-04\n",
      "Epoch 158/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.3348e-04 - val_loss: 4.1683e-04\n",
      "Epoch 159/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.1646e-04 - val_loss: 6.3579e-04\n",
      "Epoch 160/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.3049e-04 - val_loss: 4.2550e-04\n",
      "Epoch 161/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.2878e-04 - val_loss: 5.2114e-04\n",
      "Epoch 162/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.3577e-04 - val_loss: 4.5222e-04\n",
      "Epoch 163/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.4345e-04 - val_loss: 4.3269e-04\n",
      "Epoch 164/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.2014e-04 - val_loss: 4.9337e-04\n",
      "Epoch 165/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.1177e-04 - val_loss: 4.7647e-04\n",
      "Epoch 166/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.1726e-04 - val_loss: 6.0940e-04\n",
      "Epoch 167/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.1964e-04 - val_loss: 4.7479e-04\n",
      "Epoch 168/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.1008e-04 - val_loss: 4.2235e-04\n",
      "Epoch 169/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.3139e-04 - val_loss: 4.0100e-04\n",
      "Epoch 170/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.1136e-04 - val_loss: 4.4334e-04\n",
      "Epoch 171/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.1701e-04 - val_loss: 4.0710e-04\n",
      "Epoch 172/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.9850e-04 - val_loss: 5.2546e-04\n",
      "Epoch 173/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.2144e-04 - val_loss: 4.1323e-04\n",
      "Epoch 174/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.0921e-04 - val_loss: 4.0549e-04\n",
      "Epoch 175/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.0989e-04 - val_loss: 5.1805e-04\n",
      "Epoch 176/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.2188e-04 - val_loss: 4.0681e-04\n",
      "Epoch 177/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.0055e-04 - val_loss: 4.3273e-04\n",
      "Epoch 178/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.2386e-04 - val_loss: 4.4219e-04\n",
      "Epoch 179/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.2268e-04 - val_loss: 4.0820e-04\n",
      "Epoch 180/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.9706e-04 - val_loss: 3.9380e-04\n",
      "Epoch 181/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.0576e-04 - val_loss: 4.2272e-04\n",
      "Epoch 182/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.0710e-04 - val_loss: 5.0765e-04\n",
      "Epoch 183/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.9928e-04 - val_loss: 5.5206e-04\n",
      "Epoch 184/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.1402e-04 - val_loss: 4.1780e-04\n",
      "Epoch 185/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.1506e-04 - val_loss: 4.6608e-04\n",
      "Epoch 186/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.1075e-04 - val_loss: 3.8842e-04\n",
      "Epoch 187/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.9768e-04 - val_loss: 4.3350e-04\n",
      "Epoch 188/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.1634e-04 - val_loss: 4.0128e-04\n",
      "Epoch 189/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.0247e-04 - val_loss: 4.0791e-04\n",
      "Epoch 190/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.0034e-04 - val_loss: 4.2940e-04\n",
      "Epoch 191/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.9592e-04 - val_loss: 4.6433e-04\n",
      "Epoch 192/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.0844e-04 - val_loss: 4.6392e-04\n",
      "Epoch 193/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.9684e-04 - val_loss: 4.7575e-04\n",
      "Epoch 194/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.0080e-04 - val_loss: 4.5619e-04\n",
      "Epoch 195/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.7865e-04 - val_loss: 5.9156e-04\n",
      "Epoch 196/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.0649e-04 - val_loss: 4.2776e-04\n",
      "Epoch 197/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.9615e-04 - val_loss: 5.3739e-04\n",
      "Epoch 198/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.8488e-04 - val_loss: 4.7691e-04\n",
      "Epoch 199/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.9277e-04 - val_loss: 3.9407e-04\n",
      "Epoch 200/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.0329e-04 - val_loss: 3.9739e-04\n",
      "Epoch 201/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.9646e-04 - val_loss: 4.2770e-04\n",
      "Epoch 202/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.7878e-04 - val_loss: 3.9479e-04\n",
      "Epoch 203/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.2138e-04 - val_loss: 3.9854e-04\n",
      "Epoch 204/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.8701e-04 - val_loss: 4.5832e-04\n",
      "Epoch 205/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.6663e-04 - val_loss: 4.8184e-04\n",
      "Epoch 206/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.8075e-04 - val_loss: 4.0788e-04\n",
      "Epoch 207/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.8485e-04 - val_loss: 5.9091e-04\n",
      "Epoch 208/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.1154e-04 - val_loss: 3.9437e-04\n",
      "Epoch 209/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.8527e-04 - val_loss: 4.9904e-04\n",
      "Epoch 210/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.0179e-04 - val_loss: 5.7374e-04\n",
      "Epoch 211/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.8996e-04 - val_loss: 4.7802e-04\n",
      "Epoch 212/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.8131e-04 - val_loss: 3.8357e-04\n",
      "Epoch 213/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.7442e-04 - val_loss: 4.4526e-04\n",
      "Epoch 214/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.7762e-04 - val_loss: 4.1353e-04\n",
      "Epoch 215/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.8913e-04 - val_loss: 3.8262e-04\n",
      "Epoch 216/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.0278e-04 - val_loss: 3.9786e-04\n",
      "Epoch 217/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.8538e-04 - val_loss: 3.9538e-04\n",
      "Epoch 218/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.7544e-04 - val_loss: 3.9098e-04\n",
      "Epoch 219/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.9092e-04 - val_loss: 3.7636e-04\n",
      "Epoch 220/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.7742e-04 - val_loss: 4.1794e-04\n",
      "Epoch 221/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.7698e-04 - val_loss: 4.2459e-04\n",
      "Epoch 222/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.9113e-04 - val_loss: 3.6732e-04\n",
      "Epoch 223/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.8291e-04 - val_loss: 3.8980e-04\n",
      "Epoch 224/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.7187e-04 - val_loss: 3.9146e-04\n",
      "Epoch 225/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.8756e-04 - val_loss: 5.6597e-04\n",
      "Epoch 226/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.8633e-04 - val_loss: 4.2265e-04\n",
      "Epoch 227/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.6410e-04 - val_loss: 4.3515e-04\n",
      "Epoch 228/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.8589e-04 - val_loss: 8.0210e-04\n",
      "Epoch 229/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.6059e-04 - val_loss: 5.6945e-04\n",
      "Epoch 230/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5972e-04 - val_loss: 4.5923e-04\n",
      "Epoch 231/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.8541e-04 - val_loss: 3.8401e-04\n",
      "Epoch 232/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5992e-04 - val_loss: 4.0931e-04\n",
      "Epoch 233/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.6796e-04 - val_loss: 3.6235e-04\n",
      "Epoch 234/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.6399e-04 - val_loss: 3.6290e-04\n",
      "Epoch 235/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.6338e-04 - val_loss: 3.7330e-04\n",
      "Epoch 236/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.7644e-04 - val_loss: 4.5214e-04\n",
      "Epoch 237/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.7100e-04 - val_loss: 3.8979e-04\n",
      "Epoch 238/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.8147e-04 - val_loss: 3.7395e-04\n",
      "Epoch 239/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.7466e-04 - val_loss: 6.0789e-04\n",
      "Epoch 240/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.6087e-04 - val_loss: 4.1155e-04\n",
      "Epoch 241/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.7267e-04 - val_loss: 3.7943e-04\n",
      "Epoch 242/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.7640e-04 - val_loss: 3.4990e-04\n",
      "Epoch 243/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5283e-04 - val_loss: 3.7152e-04\n",
      "Epoch 244/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5864e-04 - val_loss: 4.2949e-04\n",
      "Epoch 245/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.6925e-04 - val_loss: 3.8075e-04\n",
      "Epoch 246/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.6714e-04 - val_loss: 3.9220e-04\n",
      "Epoch 247/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.6138e-04 - val_loss: 3.5598e-04\n",
      "Epoch 248/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.7243e-04 - val_loss: 4.1473e-04\n",
      "Epoch 249/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5983e-04 - val_loss: 4.0784e-04\n",
      "Epoch 250/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.6866e-04 - val_loss: 3.5687e-04\n",
      "Epoch 251/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5971e-04 - val_loss: 4.3241e-04\n",
      "Epoch 252/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4819e-04 - val_loss: 4.3941e-04\n",
      "Epoch 253/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5791e-04 - val_loss: 3.7527e-04\n",
      "Epoch 254/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5471e-04 - val_loss: 4.3898e-04\n",
      "Epoch 255/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5760e-04 - val_loss: 3.5375e-04\n",
      "Epoch 256/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4766e-04 - val_loss: 4.1679e-04\n",
      "Epoch 257/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.6889e-04 - val_loss: 3.7375e-04\n",
      "Epoch 258/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.6415e-04 - val_loss: 3.6794e-04\n",
      "Epoch 259/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4913e-04 - val_loss: 3.6867e-04\n",
      "Epoch 260/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.6103e-04 - val_loss: 4.1567e-04\n",
      "Epoch 261/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5344e-04 - val_loss: 3.7602e-04\n",
      "Epoch 262/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5194e-04 - val_loss: 4.0018e-04\n",
      "Epoch 263/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5400e-04 - val_loss: 3.6690e-04\n",
      "Epoch 264/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4369e-04 - val_loss: 4.3380e-04\n",
      "Epoch 265/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5768e-04 - val_loss: 4.4697e-04\n",
      "Epoch 266/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5669e-04 - val_loss: 3.6714e-04\n",
      "Epoch 267/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4901e-04 - val_loss: 3.8251e-04\n",
      "Epoch 268/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5577e-04 - val_loss: 3.6392e-04\n",
      "Epoch 269/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.6354e-04 - val_loss: 3.7928e-04\n",
      "Epoch 270/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4251e-04 - val_loss: 3.6904e-04\n",
      "Epoch 271/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.8009e-04 - val_loss: 3.4806e-04\n",
      "Epoch 272/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4795e-04 - val_loss: 4.4363e-04\n",
      "Epoch 273/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4896e-04 - val_loss: 3.6491e-04\n",
      "Epoch 274/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5195e-04 - val_loss: 3.9956e-04\n",
      "Epoch 275/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4431e-04 - val_loss: 3.5794e-04\n",
      "Epoch 276/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4831e-04 - val_loss: 3.5133e-04\n",
      "Epoch 277/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4790e-04 - val_loss: 3.6147e-04\n",
      "Epoch 278/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5209e-04 - val_loss: 3.5573e-04\n",
      "Epoch 279/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.3077e-04 - val_loss: 3.7108e-04\n",
      "Epoch 280/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4629e-04 - val_loss: 5.9662e-04\n",
      "Epoch 281/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5955e-04 - val_loss: 3.6487e-04\n",
      "Epoch 282/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.3446e-04 - val_loss: 4.1929e-04\n",
      "Epoch 283/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.6807e-04 - val_loss: 4.1299e-04\n",
      "Epoch 284/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4549e-04 - val_loss: 3.4957e-04\n",
      "Epoch 285/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4963e-04 - val_loss: 3.5862e-04\n",
      "Epoch 286/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4899e-04 - val_loss: 3.6397e-04\n",
      "Epoch 287/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4927e-04 - val_loss: 4.0343e-04\n",
      "Epoch 288/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5598e-04 - val_loss: 3.6222e-04\n",
      "Epoch 289/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4733e-04 - val_loss: 3.9006e-04\n",
      "Epoch 290/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4113e-04 - val_loss: 3.9175e-04\n",
      "Epoch 291/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4674e-04 - val_loss: 3.8361e-04\n",
      "Epoch 292/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2763e-04 - val_loss: 6.3789e-04\n",
      "Epoch 293/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5421e-04 - val_loss: 3.4374e-04\n",
      "Epoch 294/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5067e-04 - val_loss: 3.6627e-04\n",
      "Epoch 295/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4662e-04 - val_loss: 3.7551e-04\n",
      "Epoch 296/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.3771e-04 - val_loss: 3.8568e-04\n",
      "Epoch 297/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.3985e-04 - val_loss: 4.3623e-04\n",
      "Epoch 298/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.3353e-04 - val_loss: 4.4647e-04\n",
      "Epoch 299/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.6632e-04 - val_loss: 4.7663e-04\n",
      "Epoch 300/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4196e-04 - val_loss: 3.5722e-04\n",
      "Epoch 301/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4581e-04 - val_loss: 4.8325e-04\n",
      "Epoch 302/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5274e-04 - val_loss: 3.5578e-04\n",
      "Epoch 303/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4376e-04 - val_loss: 3.4289e-04\n",
      "Epoch 304/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4035e-04 - val_loss: 4.1929e-04\n",
      "Epoch 305/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.3086e-04 - val_loss: 3.7588e-04\n",
      "Epoch 306/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4114e-04 - val_loss: 3.8817e-04\n",
      "Epoch 307/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2147e-04 - val_loss: 3.7981e-04\n",
      "Epoch 308/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4812e-04 - val_loss: 3.5176e-04\n",
      "Epoch 309/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4523e-04 - val_loss: 3.6134e-04\n",
      "Epoch 310/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.3650e-04 - val_loss: 3.5601e-04\n",
      "Epoch 311/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2518e-04 - val_loss: 3.9250e-04\n",
      "Epoch 312/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4331e-04 - val_loss: 3.4370e-04\n",
      "Epoch 313/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.3604e-04 - val_loss: 3.4229e-04\n",
      "Epoch 314/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5170e-04 - val_loss: 3.5354e-04\n",
      "Epoch 315/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4238e-04 - val_loss: 3.9232e-04\n",
      "Epoch 316/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.3766e-04 - val_loss: 3.8284e-04\n",
      "Epoch 317/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2598e-04 - val_loss: 3.4773e-04\n",
      "Epoch 318/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2607e-04 - val_loss: 3.6565e-04\n",
      "Epoch 319/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4700e-04 - val_loss: 3.6279e-04\n",
      "Epoch 320/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2317e-04 - val_loss: 3.7827e-04\n",
      "Epoch 321/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.5262e-04 - val_loss: 3.5228e-04\n",
      "Epoch 322/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.3665e-04 - val_loss: 3.6871e-04\n",
      "Epoch 323/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2462e-04 - val_loss: 3.4681e-04\n",
      "Epoch 324/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.3275e-04 - val_loss: 3.5420e-04\n",
      "Epoch 325/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.3242e-04 - val_loss: 3.9288e-04\n",
      "Epoch 326/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.4653e-04 - val_loss: 3.3504e-04\n",
      "Epoch 327/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2454e-04 - val_loss: 4.0427e-04\n",
      "Epoch 328/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2831e-04 - val_loss: 3.4816e-04\n",
      "Epoch 329/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1658e-04 - val_loss: 4.6022e-04\n",
      "Epoch 330/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.3171e-04 - val_loss: 4.3957e-04\n",
      "Epoch 331/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.3967e-04 - val_loss: 3.2846e-04\n",
      "Epoch 332/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.3331e-04 - val_loss: 3.7292e-04\n",
      "Epoch 333/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2524e-04 - val_loss: 3.5230e-04\n",
      "Epoch 334/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2296e-04 - val_loss: 3.3400e-04\n",
      "Epoch 335/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2345e-04 - val_loss: 3.4195e-04\n",
      "Epoch 336/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2657e-04 - val_loss: 3.7368e-04\n",
      "Epoch 337/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2276e-04 - val_loss: 3.4408e-04\n",
      "Epoch 338/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.3879e-04 - val_loss: 3.3814e-04\n",
      "Epoch 339/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.3399e-04 - val_loss: 3.2755e-04\n",
      "Epoch 340/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2017e-04 - val_loss: 3.7104e-04\n",
      "Epoch 341/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1723e-04 - val_loss: 3.5295e-04\n",
      "Epoch 342/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1639e-04 - val_loss: 3.9306e-04\n",
      "Epoch 343/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2072e-04 - val_loss: 4.6843e-04\n",
      "Epoch 344/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.3570e-04 - val_loss: 3.5959e-04\n",
      "Epoch 345/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2195e-04 - val_loss: 3.7180e-04\n",
      "Epoch 346/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2314e-04 - val_loss: 3.5290e-04\n",
      "Epoch 347/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2536e-04 - val_loss: 3.3635e-04\n",
      "Epoch 348/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2597e-04 - val_loss: 3.3760e-04\n",
      "Epoch 349/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1388e-04 - val_loss: 3.5541e-04\n",
      "Epoch 350/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1642e-04 - val_loss: 3.3875e-04\n",
      "Epoch 351/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1610e-04 - val_loss: 3.4983e-04\n",
      "Epoch 352/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2249e-04 - val_loss: 4.1984e-04\n",
      "Epoch 353/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2219e-04 - val_loss: 3.4297e-04\n",
      "Epoch 354/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2156e-04 - val_loss: 3.8021e-04\n",
      "Epoch 355/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0727e-04 - val_loss: 3.7575e-04\n",
      "Epoch 356/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1628e-04 - val_loss: 3.3844e-04\n",
      "Epoch 357/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1531e-04 - val_loss: 3.3647e-04\n",
      "Epoch 358/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0801e-04 - val_loss: 3.6258e-04\n",
      "Epoch 359/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2632e-04 - val_loss: 4.0234e-04\n",
      "Epoch 360/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1322e-04 - val_loss: 3.3005e-04\n",
      "Epoch 361/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1199e-04 - val_loss: 3.6263e-04\n",
      "Epoch 362/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2642e-04 - val_loss: 4.0641e-04\n",
      "Epoch 363/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1132e-04 - val_loss: 3.5051e-04\n",
      "Epoch 364/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2206e-04 - val_loss: 3.4217e-04\n",
      "Epoch 365/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0162e-04 - val_loss: 3.2711e-04\n",
      "Epoch 366/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1112e-04 - val_loss: 3.5777e-04\n",
      "Epoch 367/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0571e-04 - val_loss: 3.5971e-04\n",
      "Epoch 368/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2478e-04 - val_loss: 3.2478e-04\n",
      "Epoch 369/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1074e-04 - val_loss: 3.6096e-04\n",
      "Epoch 370/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1803e-04 - val_loss: 3.8574e-04\n",
      "Epoch 371/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2456e-04 - val_loss: 3.4384e-04\n",
      "Epoch 372/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0507e-04 - val_loss: 3.4830e-04\n",
      "Epoch 373/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0934e-04 - val_loss: 3.4456e-04\n",
      "Epoch 374/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0261e-04 - val_loss: 4.6432e-04\n",
      "Epoch 375/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.2466e-04 - val_loss: 3.7708e-04\n",
      "Epoch 376/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0559e-04 - val_loss: 3.7383e-04\n",
      "Epoch 377/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9448e-04 - val_loss: 4.5606e-04\n",
      "Epoch 378/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1826e-04 - val_loss: 3.3030e-04\n",
      "Epoch 379/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1843e-04 - val_loss: 4.2846e-04\n",
      "Epoch 380/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1877e-04 - val_loss: 3.7008e-04\n",
      "Epoch 381/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0372e-04 - val_loss: 3.4786e-04\n",
      "Epoch 382/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9870e-04 - val_loss: 3.8955e-04\n",
      "Epoch 383/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1565e-04 - val_loss: 3.5464e-04\n",
      "Epoch 384/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0147e-04 - val_loss: 3.6154e-04\n",
      "Epoch 385/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1056e-04 - val_loss: 3.4287e-04\n",
      "Epoch 386/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1260e-04 - val_loss: 3.6218e-04\n",
      "Epoch 387/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0274e-04 - val_loss: 3.5732e-04\n",
      "Epoch 388/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0412e-04 - val_loss: 3.4946e-04\n",
      "Epoch 389/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0111e-04 - val_loss: 3.2898e-04\n",
      "Epoch 390/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9773e-04 - val_loss: 3.7262e-04\n",
      "Epoch 391/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1628e-04 - val_loss: 3.5120e-04\n",
      "Epoch 392/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0741e-04 - val_loss: 3.2439e-04\n",
      "Epoch 393/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0060e-04 - val_loss: 3.4531e-04\n",
      "Epoch 394/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9770e-04 - val_loss: 3.3585e-04\n",
      "Epoch 395/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0107e-04 - val_loss: 4.0207e-04\n",
      "Epoch 396/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1522e-04 - val_loss: 3.2726e-04\n",
      "Epoch 397/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0605e-04 - val_loss: 3.2290e-04\n",
      "Epoch 398/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1370e-04 - val_loss: 3.2025e-04\n",
      "Epoch 399/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9252e-04 - val_loss: 3.2901e-04\n",
      "Epoch 400/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0390e-04 - val_loss: 3.2475e-04\n",
      "Epoch 401/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9830e-04 - val_loss: 3.4089e-04\n",
      "Epoch 402/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0322e-04 - val_loss: 3.3173e-04\n",
      "Epoch 403/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0651e-04 - val_loss: 3.2746e-04\n",
      "Epoch 404/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0857e-04 - val_loss: 3.3212e-04\n",
      "Epoch 405/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9677e-04 - val_loss: 3.3107e-04\n",
      "Epoch 406/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9970e-04 - val_loss: 4.2720e-04\n",
      "Epoch 407/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0730e-04 - val_loss: 3.4571e-04\n",
      "Epoch 408/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9776e-04 - val_loss: 3.4258e-04\n",
      "Epoch 409/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9127e-04 - val_loss: 3.3107e-04\n",
      "Epoch 410/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9549e-04 - val_loss: 3.6511e-04\n",
      "Epoch 411/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9569e-04 - val_loss: 3.2510e-04\n",
      "Epoch 412/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1117e-04 - val_loss: 3.4756e-04\n",
      "Epoch 413/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9345e-04 - val_loss: 3.3280e-04\n",
      "Epoch 414/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9337e-04 - val_loss: 3.3568e-04\n",
      "Epoch 415/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9036e-04 - val_loss: 3.4426e-04\n",
      "Epoch 416/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9651e-04 - val_loss: 3.4828e-04\n",
      "Epoch 417/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9374e-04 - val_loss: 3.2155e-04\n",
      "Epoch 418/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0871e-04 - val_loss: 3.5002e-04\n",
      "Epoch 419/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8991e-04 - val_loss: 3.2962e-04\n",
      "Epoch 420/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9590e-04 - val_loss: 3.7355e-04\n",
      "Epoch 421/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9868e-04 - val_loss: 3.1535e-04\n",
      "Epoch 422/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9691e-04 - val_loss: 3.3817e-04\n",
      "Epoch 423/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9764e-04 - val_loss: 3.3341e-04\n",
      "Epoch 424/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9263e-04 - val_loss: 3.4964e-04\n",
      "Epoch 425/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9866e-04 - val_loss: 3.3156e-04\n",
      "Epoch 426/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0312e-04 - val_loss: 4.3183e-04\n",
      "Epoch 427/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8595e-04 - val_loss: 3.3421e-04\n",
      "Epoch 428/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0042e-04 - val_loss: 3.2985e-04\n",
      "Epoch 429/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8805e-04 - val_loss: 3.7995e-04\n",
      "Epoch 430/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0356e-04 - val_loss: 3.2285e-04\n",
      "Epoch 431/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8005e-04 - val_loss: 3.3797e-04\n",
      "Epoch 432/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.1015e-04 - val_loss: 3.2887e-04\n",
      "Epoch 433/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9819e-04 - val_loss: 3.3734e-04\n",
      "Epoch 434/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8623e-04 - val_loss: 3.2507e-04\n",
      "Epoch 435/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8812e-04 - val_loss: 3.3093e-04\n",
      "Epoch 436/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8617e-04 - val_loss: 3.1900e-04\n",
      "Epoch 437/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9936e-04 - val_loss: 3.4192e-04\n",
      "Epoch 438/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9650e-04 - val_loss: 3.3882e-04\n",
      "Epoch 439/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8961e-04 - val_loss: 3.5862e-04\n",
      "Epoch 440/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9728e-04 - val_loss: 3.2312e-04\n",
      "Epoch 441/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8980e-04 - val_loss: 3.4619e-04\n",
      "Epoch 442/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8637e-04 - val_loss: 3.3415e-04\n",
      "Epoch 443/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 3.0554e-04 - val_loss: 3.3632e-04\n",
      "Epoch 444/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7677e-04 - val_loss: 3.5547e-04\n",
      "Epoch 445/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8718e-04 - val_loss: 3.3670e-04\n",
      "Epoch 446/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7963e-04 - val_loss: 3.9102e-04\n",
      "Epoch 447/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9640e-04 - val_loss: 3.2722e-04\n",
      "Epoch 448/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8847e-04 - val_loss: 3.1710e-04\n",
      "Epoch 449/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7813e-04 - val_loss: 3.6334e-04\n",
      "Epoch 450/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9141e-04 - val_loss: 4.0253e-04\n",
      "Epoch 451/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7912e-04 - val_loss: 5.4930e-04\n",
      "Epoch 452/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9582e-04 - val_loss: 3.4407e-04\n",
      "Epoch 453/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9682e-04 - val_loss: 3.2071e-04\n",
      "Epoch 454/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7971e-04 - val_loss: 3.2152e-04\n",
      "Epoch 455/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8366e-04 - val_loss: 3.7665e-04\n",
      "Epoch 456/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8443e-04 - val_loss: 3.4485e-04\n",
      "Epoch 457/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8798e-04 - val_loss: 3.6171e-04\n",
      "Epoch 458/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8403e-04 - val_loss: 3.3387e-04\n",
      "Epoch 459/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7997e-04 - val_loss: 3.6519e-04\n",
      "Epoch 460/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9422e-04 - val_loss: 3.3106e-04\n",
      "Epoch 461/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7912e-04 - val_loss: 3.2565e-04\n",
      "Epoch 462/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7975e-04 - val_loss: 3.2768e-04\n",
      "Epoch 463/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8246e-04 - val_loss: 3.6651e-04\n",
      "Epoch 464/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8334e-04 - val_loss: 4.0987e-04\n",
      "Epoch 465/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9314e-04 - val_loss: 3.3991e-04\n",
      "Epoch 466/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8624e-04 - val_loss: 3.2358e-04\n",
      "Epoch 467/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.9222e-04 - val_loss: 3.3427e-04\n",
      "Epoch 468/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7475e-04 - val_loss: 3.3835e-04\n",
      "Epoch 469/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7996e-04 - val_loss: 3.6364e-04\n",
      "Epoch 470/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8236e-04 - val_loss: 3.5547e-04\n",
      "Epoch 471/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8563e-04 - val_loss: 3.2495e-04\n",
      "Epoch 472/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8220e-04 - val_loss: 3.2946e-04\n",
      "Epoch 473/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8439e-04 - val_loss: 3.4115e-04\n",
      "Epoch 474/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7691e-04 - val_loss: 3.2818e-04\n",
      "Epoch 475/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8962e-04 - val_loss: 3.5387e-04\n",
      "Epoch 476/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7752e-04 - val_loss: 3.4881e-04\n",
      "Epoch 477/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8109e-04 - val_loss: 3.2179e-04\n",
      "Epoch 478/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7878e-04 - val_loss: 3.4331e-04\n",
      "Epoch 479/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7247e-04 - val_loss: 3.3681e-04\n",
      "Epoch 480/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7330e-04 - val_loss: 3.3820e-04\n",
      "Epoch 481/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7961e-04 - val_loss: 3.4077e-04\n",
      "Epoch 482/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8279e-04 - val_loss: 3.1254e-04\n",
      "Epoch 483/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7603e-04 - val_loss: 3.3303e-04\n",
      "Epoch 484/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6834e-04 - val_loss: 3.2782e-04\n",
      "Epoch 485/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8707e-04 - val_loss: 3.3906e-04\n",
      "Epoch 486/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7757e-04 - val_loss: 3.3032e-04\n",
      "Epoch 487/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7302e-04 - val_loss: 3.2496e-04\n",
      "Epoch 488/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8105e-04 - val_loss: 3.6851e-04\n",
      "Epoch 489/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8323e-04 - val_loss: 3.4739e-04\n",
      "Epoch 490/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8014e-04 - val_loss: 3.2472e-04\n",
      "Epoch 491/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7154e-04 - val_loss: 3.3644e-04\n",
      "Epoch 492/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7654e-04 - val_loss: 3.2790e-04\n",
      "Epoch 493/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7960e-04 - val_loss: 3.1254e-04\n",
      "Epoch 494/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8099e-04 - val_loss: 3.4431e-04\n",
      "Epoch 495/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6920e-04 - val_loss: 3.3650e-04\n",
      "Epoch 496/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7856e-04 - val_loss: 3.3047e-04\n",
      "Epoch 497/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6809e-04 - val_loss: 3.5593e-04\n",
      "Epoch 498/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6659e-04 - val_loss: 4.1017e-04\n",
      "Epoch 499/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7289e-04 - val_loss: 3.6887e-04\n",
      "Epoch 500/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8864e-04 - val_loss: 3.1573e-04\n",
      "Epoch 501/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7978e-04 - val_loss: 3.6752e-04\n",
      "Epoch 502/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7293e-04 - val_loss: 3.6536e-04\n",
      "Epoch 503/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8232e-04 - val_loss: 3.3166e-04\n",
      "Epoch 504/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7347e-04 - val_loss: 3.1894e-04\n",
      "Epoch 505/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7521e-04 - val_loss: 3.1879e-04\n",
      "Epoch 506/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8055e-04 - val_loss: 3.3797e-04\n",
      "Epoch 507/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6664e-04 - val_loss: 3.2798e-04\n",
      "Epoch 508/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7469e-04 - val_loss: 3.3016e-04\n",
      "Epoch 509/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7166e-04 - val_loss: 4.0105e-04\n",
      "Epoch 510/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7378e-04 - val_loss: 3.2461e-04\n",
      "Epoch 511/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6522e-04 - val_loss: 3.1707e-04\n",
      "Epoch 512/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8005e-04 - val_loss: 3.4895e-04\n",
      "Epoch 513/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.8072e-04 - val_loss: 4.6984e-04\n",
      "Epoch 514/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6875e-04 - val_loss: 3.2503e-04\n",
      "Epoch 515/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6566e-04 - val_loss: 3.4049e-04\n",
      "Epoch 516/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6751e-04 - val_loss: 3.1298e-04\n",
      "Epoch 517/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6724e-04 - val_loss: 3.1961e-04\n",
      "Epoch 518/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7562e-04 - val_loss: 3.2785e-04\n",
      "Epoch 519/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6249e-04 - val_loss: 3.2820e-04\n",
      "Epoch 520/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7319e-04 - val_loss: 3.4567e-04\n",
      "Epoch 521/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6811e-04 - val_loss: 3.2104e-04\n",
      "Epoch 522/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7466e-04 - val_loss: 3.6795e-04\n",
      "Epoch 523/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6368e-04 - val_loss: 3.1825e-04\n",
      "Epoch 524/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7146e-04 - val_loss: 3.6013e-04\n",
      "Epoch 525/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6206e-04 - val_loss: 3.1688e-04\n",
      "Epoch 526/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5859e-04 - val_loss: 3.2232e-04\n",
      "Epoch 527/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7597e-04 - val_loss: 3.1385e-04\n",
      "Epoch 528/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6507e-04 - val_loss: 3.2249e-04\n",
      "Epoch 529/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5898e-04 - val_loss: 3.5321e-04\n",
      "Epoch 530/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6611e-04 - val_loss: 3.2900e-04\n",
      "Epoch 531/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7630e-04 - val_loss: 3.3794e-04\n",
      "Epoch 532/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6542e-04 - val_loss: 3.3422e-04\n",
      "Epoch 533/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6015e-04 - val_loss: 3.1378e-04\n",
      "Epoch 534/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6783e-04 - val_loss: 3.2436e-04\n",
      "Epoch 535/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6959e-04 - val_loss: 3.3277e-04\n",
      "Epoch 536/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6510e-04 - val_loss: 3.5537e-04\n",
      "Epoch 537/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7433e-04 - val_loss: 3.3856e-04\n",
      "Epoch 538/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6795e-04 - val_loss: 3.1512e-04\n",
      "Epoch 539/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7066e-04 - val_loss: 3.4945e-04\n",
      "Epoch 540/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6443e-04 - val_loss: 3.7081e-04\n",
      "Epoch 541/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.7150e-04 - val_loss: 3.5170e-04\n",
      "Epoch 542/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5358e-04 - val_loss: 3.4721e-04\n",
      "Epoch 543/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6840e-04 - val_loss: 3.4140e-04\n",
      "Epoch 544/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6552e-04 - val_loss: 3.2973e-04\n",
      "Epoch 545/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5491e-04 - val_loss: 3.6919e-04\n",
      "Epoch 546/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6118e-04 - val_loss: 3.2368e-04\n",
      "Epoch 547/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6699e-04 - val_loss: 3.1951e-04\n",
      "Epoch 548/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6965e-04 - val_loss: 3.3178e-04\n",
      "Epoch 549/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6398e-04 - val_loss: 3.8996e-04\n",
      "Epoch 550/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5881e-04 - val_loss: 3.2841e-04\n",
      "Epoch 551/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5548e-04 - val_loss: 3.2860e-04\n",
      "Epoch 552/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5938e-04 - val_loss: 4.1012e-04\n",
      "Epoch 553/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5619e-04 - val_loss: 3.4178e-04\n",
      "Epoch 554/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5939e-04 - val_loss: 3.4623e-04\n",
      "Epoch 555/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6458e-04 - val_loss: 3.1021e-04\n",
      "Epoch 556/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5243e-04 - val_loss: 3.3218e-04\n",
      "Epoch 557/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6684e-04 - val_loss: 3.6515e-04\n",
      "Epoch 558/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5616e-04 - val_loss: 3.2791e-04\n",
      "Epoch 559/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6831e-04 - val_loss: 3.1497e-04\n",
      "Epoch 560/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6002e-04 - val_loss: 3.1680e-04\n",
      "Epoch 561/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6133e-04 - val_loss: 3.2769e-04\n",
      "Epoch 562/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5229e-04 - val_loss: 3.2696e-04\n",
      "Epoch 563/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6646e-04 - val_loss: 3.4793e-04\n",
      "Epoch 564/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5363e-04 - val_loss: 3.1731e-04\n",
      "Epoch 565/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6226e-04 - val_loss: 3.1880e-04\n",
      "Epoch 566/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5793e-04 - val_loss: 3.6307e-04\n",
      "Epoch 567/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6722e-04 - val_loss: 3.1555e-04\n",
      "Epoch 568/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5393e-04 - val_loss: 3.2579e-04\n",
      "Epoch 569/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6649e-04 - val_loss: 3.2315e-04\n",
      "Epoch 570/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4841e-04 - val_loss: 3.2529e-04\n",
      "Epoch 571/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6730e-04 - val_loss: 3.3399e-04\n",
      "Epoch 572/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5249e-04 - val_loss: 3.1820e-04\n",
      "Epoch 573/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5483e-04 - val_loss: 3.3587e-04\n",
      "Epoch 574/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5716e-04 - val_loss: 3.3659e-04\n",
      "Epoch 575/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5137e-04 - val_loss: 3.0618e-04\n",
      "Epoch 576/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6197e-04 - val_loss: 3.2001e-04\n",
      "Epoch 577/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5475e-04 - val_loss: 3.2643e-04\n",
      "Epoch 578/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5224e-04 - val_loss: 3.1238e-04\n",
      "Epoch 579/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5367e-04 - val_loss: 3.5770e-04\n",
      "Epoch 580/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6307e-04 - val_loss: 3.4771e-04\n",
      "Epoch 581/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5838e-04 - val_loss: 3.0859e-04\n",
      "Epoch 582/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5634e-04 - val_loss: 3.2519e-04\n",
      "Epoch 583/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5426e-04 - val_loss: 3.2724e-04\n",
      "Epoch 584/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5572e-04 - val_loss: 3.0692e-04\n",
      "Epoch 585/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5419e-04 - val_loss: 4.4985e-04\n",
      "Epoch 586/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6062e-04 - val_loss: 3.1814e-04\n",
      "Epoch 587/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5086e-04 - val_loss: 3.1708e-04\n",
      "Epoch 588/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5250e-04 - val_loss: 3.2406e-04\n",
      "Epoch 589/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4878e-04 - val_loss: 3.8084e-04\n",
      "Epoch 590/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5750e-04 - val_loss: 3.1670e-04\n",
      "Epoch 591/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6388e-04 - val_loss: 3.2055e-04\n",
      "Epoch 592/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4893e-04 - val_loss: 3.2229e-04\n",
      "Epoch 593/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5232e-04 - val_loss: 3.4177e-04\n",
      "Epoch 594/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5486e-04 - val_loss: 3.2311e-04\n",
      "Epoch 595/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5671e-04 - val_loss: 3.1778e-04\n",
      "Epoch 596/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5263e-04 - val_loss: 3.2938e-04\n",
      "Epoch 597/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5996e-04 - val_loss: 3.1959e-04\n",
      "Epoch 598/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6058e-04 - val_loss: 3.6124e-04\n",
      "Epoch 599/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4430e-04 - val_loss: 3.4541e-04\n",
      "Epoch 600/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4462e-04 - val_loss: 3.2759e-04\n",
      "Epoch 601/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5866e-04 - val_loss: 3.6122e-04\n",
      "Epoch 602/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5530e-04 - val_loss: 3.1241e-04\n",
      "Epoch 603/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4741e-04 - val_loss: 3.3223e-04\n",
      "Epoch 604/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5539e-04 - val_loss: 3.4249e-04\n",
      "Epoch 605/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5063e-04 - val_loss: 3.1840e-04\n",
      "Epoch 606/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5378e-04 - val_loss: 3.3562e-04\n",
      "Epoch 607/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3991e-04 - val_loss: 3.3076e-04\n",
      "Epoch 608/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5460e-04 - val_loss: 3.2764e-04\n",
      "Epoch 609/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4675e-04 - val_loss: 3.3763e-04\n",
      "Epoch 610/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4327e-04 - val_loss: 4.3217e-04\n",
      "Epoch 611/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.6121e-04 - val_loss: 3.4152e-04\n",
      "Epoch 612/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5201e-04 - val_loss: 4.0513e-04\n",
      "Epoch 613/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5011e-04 - val_loss: 3.2725e-04\n",
      "Epoch 614/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4530e-04 - val_loss: 3.1223e-04\n",
      "Epoch 615/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4754e-04 - val_loss: 3.4565e-04\n",
      "Epoch 616/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4967e-04 - val_loss: 3.8256e-04\n",
      "Epoch 617/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4602e-04 - val_loss: 3.7400e-04\n",
      "Epoch 618/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4776e-04 - val_loss: 3.4199e-04\n",
      "Epoch 619/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4605e-04 - val_loss: 3.3827e-04\n",
      "Epoch 620/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5266e-04 - val_loss: 3.3152e-04\n",
      "Epoch 621/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4468e-04 - val_loss: 3.2031e-04\n",
      "Epoch 622/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4702e-04 - val_loss: 3.2278e-04\n",
      "Epoch 623/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4413e-04 - val_loss: 3.6334e-04\n",
      "Epoch 624/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4010e-04 - val_loss: 3.2017e-04\n",
      "Epoch 625/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5374e-04 - val_loss: 4.0939e-04\n",
      "Epoch 626/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4949e-04 - val_loss: 3.4011e-04\n",
      "Epoch 627/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5041e-04 - val_loss: 3.2489e-04\n",
      "Epoch 628/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4486e-04 - val_loss: 3.1658e-04\n",
      "Epoch 629/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4875e-04 - val_loss: 3.5346e-04\n",
      "Epoch 630/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4926e-04 - val_loss: 3.1593e-04\n",
      "Epoch 631/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3535e-04 - val_loss: 3.1923e-04\n",
      "Epoch 632/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5102e-04 - val_loss: 3.2354e-04\n",
      "Epoch 633/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3646e-04 - val_loss: 3.2052e-04\n",
      "Epoch 634/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4534e-04 - val_loss: 3.3026e-04\n",
      "Epoch 635/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.5598e-04 - val_loss: 3.1611e-04\n",
      "Epoch 636/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4109e-04 - val_loss: 3.0740e-04\n",
      "Epoch 637/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3255e-04 - val_loss: 3.4265e-04\n",
      "Epoch 638/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4754e-04 - val_loss: 3.2426e-04\n",
      "Epoch 639/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3640e-04 - val_loss: 3.4356e-04\n",
      "Epoch 640/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4412e-04 - val_loss: 3.2266e-04\n",
      "Epoch 641/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4292e-04 - val_loss: 3.1702e-04\n",
      "Epoch 642/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4853e-04 - val_loss: 3.2957e-04\n",
      "Epoch 643/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4513e-04 - val_loss: 3.2813e-04\n",
      "Epoch 644/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4770e-04 - val_loss: 3.3771e-04\n",
      "Epoch 645/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4168e-04 - val_loss: 3.2231e-04\n",
      "Epoch 646/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4255e-04 - val_loss: 3.2950e-04\n",
      "Epoch 647/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4090e-04 - val_loss: 3.1253e-04\n",
      "Epoch 648/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4064e-04 - val_loss: 3.5674e-04\n",
      "Epoch 649/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4266e-04 - val_loss: 3.5488e-04\n",
      "Epoch 650/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4175e-04 - val_loss: 3.4167e-04\n",
      "Epoch 651/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4080e-04 - val_loss: 3.4660e-04\n",
      "Epoch 652/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4759e-04 - val_loss: 3.2534e-04\n",
      "Epoch 653/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3484e-04 - val_loss: 3.1812e-04\n",
      "Epoch 654/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4364e-04 - val_loss: 3.2457e-04\n",
      "Epoch 655/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4479e-04 - val_loss: 3.4237e-04\n",
      "Epoch 656/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4887e-04 - val_loss: 3.3819e-04\n",
      "Epoch 657/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3225e-04 - val_loss: 3.1338e-04\n",
      "Epoch 658/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4385e-04 - val_loss: 3.3474e-04\n",
      "Epoch 659/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3811e-04 - val_loss: 3.3256e-04\n",
      "Epoch 660/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3281e-04 - val_loss: 3.3052e-04\n",
      "Epoch 661/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4078e-04 - val_loss: 3.2672e-04\n",
      "Epoch 662/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4215e-04 - val_loss: 3.1813e-04\n",
      "Epoch 663/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3606e-04 - val_loss: 3.4523e-04\n",
      "Epoch 664/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3656e-04 - val_loss: 3.3027e-04\n",
      "Epoch 665/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3472e-04 - val_loss: 3.5086e-04\n",
      "Epoch 666/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4309e-04 - val_loss: 3.2101e-04\n",
      "Epoch 667/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4458e-04 - val_loss: 3.7012e-04\n",
      "Epoch 668/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3530e-04 - val_loss: 3.3385e-04\n",
      "Epoch 669/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3827e-04 - val_loss: 3.3337e-04\n",
      "Epoch 670/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3215e-04 - val_loss: 3.3707e-04\n",
      "Epoch 671/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3509e-04 - val_loss: 3.3361e-04\n",
      "Epoch 672/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3715e-04 - val_loss: 3.2286e-04\n",
      "Epoch 673/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4031e-04 - val_loss: 3.3604e-04\n",
      "Epoch 674/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3797e-04 - val_loss: 3.4163e-04\n",
      "Epoch 675/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3790e-04 - val_loss: 3.1098e-04\n",
      "Epoch 676/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3810e-04 - val_loss: 3.2433e-04\n",
      "Epoch 677/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3586e-04 - val_loss: 3.3205e-04\n",
      "Epoch 678/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3019e-04 - val_loss: 3.3338e-04\n",
      "Epoch 679/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3835e-04 - val_loss: 3.3234e-04\n",
      "Epoch 680/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2971e-04 - val_loss: 3.4613e-04\n",
      "Epoch 681/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3598e-04 - val_loss: 3.3511e-04\n",
      "Epoch 682/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2946e-04 - val_loss: 3.5768e-04\n",
      "Epoch 683/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3813e-04 - val_loss: 3.2851e-04\n",
      "Epoch 684/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2391e-04 - val_loss: 3.3558e-04\n",
      "Epoch 685/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3616e-04 - val_loss: 3.3905e-04\n",
      "Epoch 686/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3339e-04 - val_loss: 3.6058e-04\n",
      "Epoch 687/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3574e-04 - val_loss: 3.3996e-04\n",
      "Epoch 688/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3018e-04 - val_loss: 3.1480e-04\n",
      "Epoch 689/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3157e-04 - val_loss: 3.4146e-04\n",
      "Epoch 690/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4774e-04 - val_loss: 3.2823e-04\n",
      "Epoch 691/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3187e-04 - val_loss: 3.3627e-04\n",
      "Epoch 692/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3258e-04 - val_loss: 3.5528e-04\n",
      "Epoch 693/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3476e-04 - val_loss: 3.1747e-04\n",
      "Epoch 694/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3021e-04 - val_loss: 3.1646e-04\n",
      "Epoch 695/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3102e-04 - val_loss: 3.1936e-04\n",
      "Epoch 696/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2543e-04 - val_loss: 3.5141e-04\n",
      "Epoch 697/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2691e-04 - val_loss: 4.6041e-04\n",
      "Epoch 698/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3363e-04 - val_loss: 3.3877e-04\n",
      "Epoch 699/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3805e-04 - val_loss: 3.2358e-04\n",
      "Epoch 700/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2185e-04 - val_loss: 3.1980e-04\n",
      "Epoch 701/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.4257e-04 - val_loss: 3.2406e-04\n",
      "Epoch 702/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3169e-04 - val_loss: 3.2130e-04\n",
      "Epoch 703/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3819e-04 - val_loss: 3.6083e-04\n",
      "Epoch 704/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2423e-04 - val_loss: 3.1891e-04\n",
      "Epoch 705/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2685e-04 - val_loss: 3.3730e-04\n",
      "Epoch 706/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3131e-04 - val_loss: 3.4256e-04\n",
      "Epoch 707/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2852e-04 - val_loss: 3.8925e-04\n",
      "Epoch 708/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3438e-04 - val_loss: 3.2668e-04\n",
      "Epoch 709/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2898e-04 - val_loss: 3.4328e-04\n",
      "Epoch 710/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3165e-04 - val_loss: 3.1171e-04\n",
      "Epoch 711/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2835e-04 - val_loss: 3.4973e-04\n",
      "Epoch 712/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2712e-04 - val_loss: 3.3734e-04\n",
      "Epoch 713/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2826e-04 - val_loss: 3.5396e-04\n",
      "Epoch 714/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2826e-04 - val_loss: 3.4649e-04\n",
      "Epoch 715/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2492e-04 - val_loss: 3.4044e-04\n",
      "Epoch 716/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3349e-04 - val_loss: 3.3708e-04\n",
      "Epoch 717/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2521e-04 - val_loss: 3.4229e-04\n",
      "Epoch 718/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3754e-04 - val_loss: 3.2981e-04\n",
      "Epoch 719/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2491e-04 - val_loss: 3.3241e-04\n",
      "Epoch 720/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2776e-04 - val_loss: 3.2331e-04\n",
      "Epoch 721/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2577e-04 - val_loss: 3.2497e-04\n",
      "Epoch 722/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3102e-04 - val_loss: 3.1965e-04\n",
      "Epoch 723/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2783e-04 - val_loss: 3.2181e-04\n",
      "Epoch 724/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2896e-04 - val_loss: 3.4126e-04\n",
      "Epoch 725/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3320e-04 - val_loss: 3.2827e-04\n",
      "Epoch 726/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2719e-04 - val_loss: 3.2794e-04\n",
      "Epoch 727/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2430e-04 - val_loss: 3.1897e-04\n",
      "Epoch 728/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2765e-04 - val_loss: 3.4183e-04\n",
      "Epoch 729/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2625e-04 - val_loss: 3.2639e-04\n",
      "Epoch 730/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2686e-04 - val_loss: 3.2051e-04\n",
      "Epoch 731/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1919e-04 - val_loss: 3.4105e-04\n",
      "Epoch 732/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3420e-04 - val_loss: 3.1814e-04\n",
      "Epoch 733/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2971e-04 - val_loss: 3.5442e-04\n",
      "Epoch 734/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2180e-04 - val_loss: 3.3110e-04\n",
      "Epoch 735/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2782e-04 - val_loss: 3.3837e-04\n",
      "Epoch 736/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2505e-04 - val_loss: 3.0874e-04\n",
      "Epoch 737/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2595e-04 - val_loss: 3.1641e-04\n",
      "Epoch 738/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2572e-04 - val_loss: 3.1558e-04\n",
      "Epoch 739/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2523e-04 - val_loss: 3.2816e-04\n",
      "Epoch 740/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2492e-04 - val_loss: 3.2256e-04\n",
      "Epoch 741/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2369e-04 - val_loss: 3.4781e-04\n",
      "Epoch 742/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2727e-04 - val_loss: 3.3055e-04\n",
      "Epoch 743/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1961e-04 - val_loss: 3.3050e-04\n",
      "Epoch 744/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2921e-04 - val_loss: 3.3218e-04\n",
      "Epoch 745/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2010e-04 - val_loss: 3.3363e-04\n",
      "Epoch 746/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2357e-04 - val_loss: 3.2420e-04\n",
      "Epoch 747/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2657e-04 - val_loss: 3.1670e-04\n",
      "Epoch 748/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2061e-04 - val_loss: 3.2483e-04\n",
      "Epoch 749/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3038e-04 - val_loss: 3.2039e-04\n",
      "Epoch 750/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2478e-04 - val_loss: 3.3786e-04\n",
      "Epoch 751/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2013e-04 - val_loss: 3.2992e-04\n",
      "Epoch 752/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2574e-04 - val_loss: 3.2010e-04\n",
      "Epoch 753/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1290e-04 - val_loss: 3.2199e-04\n",
      "Epoch 754/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2551e-04 - val_loss: 3.2773e-04\n",
      "Epoch 755/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2415e-04 - val_loss: 3.4544e-04\n",
      "Epoch 756/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2425e-04 - val_loss: 3.3348e-04\n",
      "Epoch 757/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1898e-04 - val_loss: 3.4362e-04\n",
      "Epoch 758/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1840e-04 - val_loss: 3.6993e-04\n",
      "Epoch 759/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2827e-04 - val_loss: 3.5815e-04\n",
      "Epoch 760/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1881e-04 - val_loss: 3.1885e-04\n",
      "Epoch 761/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2093e-04 - val_loss: 3.2035e-04\n",
      "Epoch 762/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1358e-04 - val_loss: 3.3293e-04\n",
      "Epoch 763/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3448e-04 - val_loss: 3.1585e-04\n",
      "Epoch 764/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2452e-04 - val_loss: 3.2163e-04\n",
      "Epoch 765/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1642e-04 - val_loss: 3.7270e-04\n",
      "Epoch 766/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1755e-04 - val_loss: 3.2018e-04\n",
      "Epoch 767/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2507e-04 - val_loss: 3.1701e-04\n",
      "Epoch 768/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1924e-04 - val_loss: 3.3348e-04\n",
      "Epoch 769/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1796e-04 - val_loss: 3.3827e-04\n",
      "Epoch 770/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2403e-04 - val_loss: 3.2329e-04\n",
      "Epoch 771/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1753e-04 - val_loss: 3.6165e-04\n",
      "Epoch 772/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2187e-04 - val_loss: 3.0942e-04\n",
      "Epoch 773/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0775e-04 - val_loss: 3.2072e-04\n",
      "Epoch 774/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.3238e-04 - val_loss: 3.1776e-04\n",
      "Epoch 775/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1588e-04 - val_loss: 3.3701e-04\n",
      "Epoch 776/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2022e-04 - val_loss: 3.3954e-04\n",
      "Epoch 777/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1668e-04 - val_loss: 3.2869e-04\n",
      "Epoch 778/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2158e-04 - val_loss: 3.2088e-04\n",
      "Epoch 779/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2361e-04 - val_loss: 3.1804e-04\n",
      "Epoch 780/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1594e-04 - val_loss: 3.4521e-04\n",
      "Epoch 781/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2304e-04 - val_loss: 3.1330e-04\n",
      "Epoch 782/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2214e-04 - val_loss: 3.5122e-04\n",
      "Epoch 783/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1117e-04 - val_loss: 3.2967e-04\n",
      "Epoch 784/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1357e-04 - val_loss: 3.3334e-04\n",
      "Epoch 785/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1674e-04 - val_loss: 3.7941e-04\n",
      "Epoch 786/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1845e-04 - val_loss: 3.3696e-04\n",
      "Epoch 787/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1635e-04 - val_loss: 3.8305e-04\n",
      "Epoch 788/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2431e-04 - val_loss: 3.2912e-04\n",
      "Epoch 789/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1175e-04 - val_loss: 3.2212e-04\n",
      "Epoch 790/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1628e-04 - val_loss: 3.4492e-04\n",
      "Epoch 791/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1823e-04 - val_loss: 4.0294e-04\n",
      "Epoch 792/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1620e-04 - val_loss: 3.3860e-04\n",
      "Epoch 793/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1247e-04 - val_loss: 3.2503e-04\n",
      "Epoch 794/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2337e-04 - val_loss: 3.3894e-04\n",
      "Epoch 795/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2034e-04 - val_loss: 3.1592e-04\n",
      "Epoch 796/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1550e-04 - val_loss: 3.2966e-04\n",
      "Epoch 797/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2125e-04 - val_loss: 3.3197e-04\n",
      "Epoch 798/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1206e-04 - val_loss: 3.4354e-04\n",
      "Epoch 799/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1243e-04 - val_loss: 3.5797e-04\n",
      "Epoch 800/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1916e-04 - val_loss: 3.7315e-04\n",
      "Epoch 801/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1607e-04 - val_loss: 3.4971e-04\n",
      "Epoch 802/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1377e-04 - val_loss: 3.2225e-04\n",
      "Epoch 803/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1828e-04 - val_loss: 3.2765e-04\n",
      "Epoch 804/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1045e-04 - val_loss: 3.4594e-04\n",
      "Epoch 805/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1745e-04 - val_loss: 3.2716e-04\n",
      "Epoch 806/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1555e-04 - val_loss: 3.2825e-04\n",
      "Epoch 807/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1765e-04 - val_loss: 3.1311e-04\n",
      "Epoch 808/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1282e-04 - val_loss: 3.2557e-04\n",
      "Epoch 809/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0870e-04 - val_loss: 3.2652e-04\n",
      "Epoch 810/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0774e-04 - val_loss: 3.9961e-04\n",
      "Epoch 811/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1557e-04 - val_loss: 3.2945e-04\n",
      "Epoch 812/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1032e-04 - val_loss: 3.4492e-04\n",
      "Epoch 813/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1080e-04 - val_loss: 3.4458e-04\n",
      "Epoch 814/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1004e-04 - val_loss: 3.2909e-04\n",
      "Epoch 815/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1023e-04 - val_loss: 3.3025e-04\n",
      "Epoch 816/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1831e-04 - val_loss: 3.3895e-04\n",
      "Epoch 817/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0774e-04 - val_loss: 3.8981e-04\n",
      "Epoch 818/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1548e-04 - val_loss: 3.3958e-04\n",
      "Epoch 819/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1739e-04 - val_loss: 3.3297e-04\n",
      "Epoch 820/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0476e-04 - val_loss: 4.3923e-04\n",
      "Epoch 821/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1687e-04 - val_loss: 3.2720e-04\n",
      "Epoch 822/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1829e-04 - val_loss: 3.3435e-04\n",
      "Epoch 823/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2076e-04 - val_loss: 3.2584e-04\n",
      "Epoch 824/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0654e-04 - val_loss: 3.8185e-04\n",
      "Epoch 825/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0882e-04 - val_loss: 3.5526e-04\n",
      "Epoch 826/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1044e-04 - val_loss: 3.4969e-04\n",
      "Epoch 827/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1045e-04 - val_loss: 3.3441e-04\n",
      "Epoch 828/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0666e-04 - val_loss: 3.4758e-04\n",
      "Epoch 829/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1529e-04 - val_loss: 3.4159e-04\n",
      "Epoch 830/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1225e-04 - val_loss: 3.2095e-04\n",
      "Epoch 831/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1097e-04 - val_loss: 3.7996e-04\n",
      "Epoch 832/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1076e-04 - val_loss: 3.2741e-04\n",
      "Epoch 833/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0357e-04 - val_loss: 3.2857e-04\n",
      "Epoch 834/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1150e-04 - val_loss: 3.7575e-04\n",
      "Epoch 835/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1523e-04 - val_loss: 3.3507e-04\n",
      "Epoch 836/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1436e-04 - val_loss: 3.3007e-04\n",
      "Epoch 837/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0317e-04 - val_loss: 3.6026e-04\n",
      "Epoch 838/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1691e-04 - val_loss: 3.3569e-04\n",
      "Epoch 839/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0532e-04 - val_loss: 4.0360e-04\n",
      "Epoch 840/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1224e-04 - val_loss: 3.4083e-04\n",
      "Epoch 841/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1118e-04 - val_loss: 3.3397e-04\n",
      "Epoch 842/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0964e-04 - val_loss: 3.2828e-04\n",
      "Epoch 843/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0514e-04 - val_loss: 3.3252e-04\n",
      "Epoch 844/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1161e-04 - val_loss: 3.3769e-04\n",
      "Epoch 845/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0703e-04 - val_loss: 3.6341e-04\n",
      "Epoch 846/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0874e-04 - val_loss: 3.2787e-04\n",
      "Epoch 847/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0816e-04 - val_loss: 3.4153e-04\n",
      "Epoch 848/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0903e-04 - val_loss: 3.4145e-04\n",
      "Epoch 849/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1022e-04 - val_loss: 3.6719e-04\n",
      "Epoch 850/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0707e-04 - val_loss: 3.3176e-04\n",
      "Epoch 851/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0767e-04 - val_loss: 3.3641e-04\n",
      "Epoch 852/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1087e-04 - val_loss: 3.2927e-04\n",
      "Epoch 853/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0608e-04 - val_loss: 3.4655e-04\n",
      "Epoch 854/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1238e-04 - val_loss: 3.5633e-04\n",
      "Epoch 855/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0556e-04 - val_loss: 3.6288e-04\n",
      "Epoch 856/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1173e-04 - val_loss: 3.4184e-04\n",
      "Epoch 857/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0440e-04 - val_loss: 3.5279e-04\n",
      "Epoch 858/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0800e-04 - val_loss: 3.5066e-04\n",
      "Epoch 859/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0938e-04 - val_loss: 3.3054e-04\n",
      "Epoch 860/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0911e-04 - val_loss: 3.5441e-04\n",
      "Epoch 861/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0624e-04 - val_loss: 3.5153e-04\n",
      "Epoch 862/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0208e-04 - val_loss: 3.3595e-04\n",
      "Epoch 863/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1192e-04 - val_loss: 3.6333e-04\n",
      "Epoch 864/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0413e-04 - val_loss: 3.5043e-04\n",
      "Epoch 865/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1797e-04 - val_loss: 3.4241e-04\n",
      "Epoch 866/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0537e-04 - val_loss: 3.2575e-04\n",
      "Epoch 867/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0157e-04 - val_loss: 3.2025e-04\n",
      "Epoch 868/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0455e-04 - val_loss: 3.8406e-04\n",
      "Epoch 869/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0771e-04 - val_loss: 3.3389e-04\n",
      "Epoch 870/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0362e-04 - val_loss: 3.3371e-04\n",
      "Epoch 871/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1051e-04 - val_loss: 3.5523e-04\n",
      "Epoch 872/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0867e-04 - val_loss: 3.7604e-04\n",
      "Epoch 873/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0176e-04 - val_loss: 3.4415e-04\n",
      "Epoch 874/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0528e-04 - val_loss: 3.2966e-04\n",
      "Epoch 875/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0539e-04 - val_loss: 3.3117e-04\n",
      "Epoch 876/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0015e-04 - val_loss: 3.2476e-04\n",
      "Epoch 877/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9711e-04 - val_loss: 3.6398e-04\n",
      "Epoch 878/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0567e-04 - val_loss: 3.5913e-04\n",
      "Epoch 879/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1408e-04 - val_loss: 3.2279e-04\n",
      "Epoch 880/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9647e-04 - val_loss: 3.6217e-04\n",
      "Epoch 881/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0488e-04 - val_loss: 3.4221e-04\n",
      "Epoch 882/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0414e-04 - val_loss: 3.2640e-04\n",
      "Epoch 883/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1152e-04 - val_loss: 3.4925e-04\n",
      "Epoch 884/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.1073e-04 - val_loss: 3.4322e-04\n",
      "Epoch 885/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9855e-04 - val_loss: 3.5568e-04\n",
      "Epoch 886/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0258e-04 - val_loss: 3.3964e-04\n",
      "Epoch 887/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0373e-04 - val_loss: 3.6046e-04\n",
      "Epoch 888/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0620e-04 - val_loss: 3.3133e-04\n",
      "Epoch 889/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9821e-04 - val_loss: 3.3700e-04\n",
      "Epoch 890/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0267e-04 - val_loss: 3.2347e-04\n",
      "Epoch 891/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0430e-04 - val_loss: 3.4959e-04\n",
      "Epoch 892/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0276e-04 - val_loss: 3.2164e-04\n",
      "Epoch 893/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0171e-04 - val_loss: 3.3062e-04\n",
      "Epoch 894/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0371e-04 - val_loss: 3.2266e-04\n",
      "Epoch 895/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0829e-04 - val_loss: 3.3339e-04\n",
      "Epoch 896/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0164e-04 - val_loss: 4.6469e-04\n",
      "Epoch 897/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0426e-04 - val_loss: 3.2784e-04\n",
      "Epoch 898/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0148e-04 - val_loss: 3.2688e-04\n",
      "Epoch 899/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0609e-04 - val_loss: 3.4328e-04\n",
      "Epoch 900/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9759e-04 - val_loss: 3.3920e-04\n",
      "Epoch 901/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0072e-04 - val_loss: 3.4352e-04\n",
      "Epoch 902/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0604e-04 - val_loss: 3.4461e-04\n",
      "Epoch 903/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0369e-04 - val_loss: 3.2713e-04\n",
      "Epoch 904/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9781e-04 - val_loss: 3.2864e-04\n",
      "Epoch 905/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9903e-04 - val_loss: 3.7184e-04\n",
      "Epoch 906/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0512e-04 - val_loss: 3.4056e-04\n",
      "Epoch 907/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0341e-04 - val_loss: 3.2659e-04\n",
      "Epoch 908/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9888e-04 - val_loss: 3.3429e-04\n",
      "Epoch 909/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0131e-04 - val_loss: 3.5160e-04\n",
      "Epoch 910/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0130e-04 - val_loss: 3.3017e-04\n",
      "Epoch 911/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9974e-04 - val_loss: 3.2636e-04\n",
      "Epoch 912/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9940e-04 - val_loss: 3.3097e-04\n",
      "Epoch 913/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0271e-04 - val_loss: 3.3565e-04\n",
      "Epoch 914/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9590e-04 - val_loss: 3.3170e-04\n",
      "Epoch 915/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0319e-04 - val_loss: 3.5860e-04\n",
      "Epoch 916/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0759e-04 - val_loss: 3.2729e-04\n",
      "Epoch 917/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9241e-04 - val_loss: 3.3565e-04\n",
      "Epoch 918/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9558e-04 - val_loss: 3.3419e-04\n",
      "Epoch 919/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9996e-04 - val_loss: 3.5265e-04\n",
      "Epoch 920/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9557e-04 - val_loss: 3.2785e-04\n",
      "Epoch 921/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9967e-04 - val_loss: 3.5416e-04\n",
      "Epoch 922/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0934e-04 - val_loss: 4.0616e-04\n",
      "Epoch 923/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9387e-04 - val_loss: 3.5854e-04\n",
      "Epoch 924/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0123e-04 - val_loss: 3.6170e-04\n",
      "Epoch 925/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9986e-04 - val_loss: 3.4355e-04\n",
      "Epoch 926/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9439e-04 - val_loss: 3.5338e-04\n",
      "Epoch 927/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9696e-04 - val_loss: 3.3573e-04\n",
      "Epoch 928/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9917e-04 - val_loss: 4.1725e-04\n",
      "Epoch 929/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9836e-04 - val_loss: 3.2826e-04\n",
      "Epoch 930/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9509e-04 - val_loss: 3.3923e-04\n",
      "Epoch 931/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9820e-04 - val_loss: 3.2715e-04\n",
      "Epoch 932/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9443e-04 - val_loss: 3.2981e-04\n",
      "Epoch 933/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0405e-04 - val_loss: 3.5360e-04\n",
      "Epoch 934/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9692e-04 - val_loss: 3.3329e-04\n",
      "Epoch 935/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9808e-04 - val_loss: 3.4106e-04\n",
      "Epoch 936/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9969e-04 - val_loss: 3.4078e-04\n",
      "Epoch 937/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9832e-04 - val_loss: 3.3392e-04\n",
      "Epoch 938/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0354e-04 - val_loss: 3.9147e-04\n",
      "Epoch 939/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0340e-04 - val_loss: 3.3595e-04\n",
      "Epoch 940/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9598e-04 - val_loss: 3.3374e-04\n",
      "Epoch 941/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9537e-04 - val_loss: 3.8225e-04\n",
      "Epoch 942/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9596e-04 - val_loss: 3.2435e-04\n",
      "Epoch 943/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9443e-04 - val_loss: 3.2188e-04\n",
      "Epoch 944/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.8946e-04 - val_loss: 3.5410e-04\n",
      "Epoch 945/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9663e-04 - val_loss: 3.7058e-04\n",
      "Epoch 946/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0210e-04 - val_loss: 3.5387e-04\n",
      "Epoch 947/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9332e-04 - val_loss: 3.3715e-04\n",
      "Epoch 948/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9383e-04 - val_loss: 3.4755e-04\n",
      "Epoch 949/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9586e-04 - val_loss: 3.4267e-04\n",
      "Epoch 950/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9483e-04 - val_loss: 3.3862e-04\n",
      "Epoch 951/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9902e-04 - val_loss: 3.3548e-04\n",
      "Epoch 952/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9342e-04 - val_loss: 3.5590e-04\n",
      "Epoch 953/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9730e-04 - val_loss: 3.5220e-04\n",
      "Epoch 954/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9170e-04 - val_loss: 3.3566e-04\n",
      "Epoch 955/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9365e-04 - val_loss: 3.7654e-04\n",
      "Epoch 956/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9623e-04 - val_loss: 3.3045e-04\n",
      "Epoch 957/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 4.1583e-04 - val_loss: 3.7052e-04\n",
      "Epoch 958/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.2089e-04 - val_loss: 3.2593e-04\n",
      "Epoch 959/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0550e-04 - val_loss: 3.2135e-04\n",
      "Epoch 960/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.8965e-04 - val_loss: 3.3740e-04\n",
      "Epoch 961/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9770e-04 - val_loss: 3.3668e-04\n",
      "Epoch 962/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0378e-04 - val_loss: 3.7087e-04\n",
      "Epoch 963/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9566e-04 - val_loss: 4.1025e-04\n",
      "Epoch 964/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9568e-04 - val_loss: 3.4646e-04\n",
      "Epoch 965/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0087e-04 - val_loss: 3.6345e-04\n",
      "Epoch 966/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9359e-04 - val_loss: 4.6155e-04\n",
      "Epoch 967/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9293e-04 - val_loss: 3.3256e-04\n",
      "Epoch 968/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 2.0012e-04 - val_loss: 3.5955e-04\n",
      "Epoch 969/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9001e-04 - val_loss: 3.4413e-04\n",
      "Epoch 970/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9530e-04 - val_loss: 3.6754e-04\n",
      "Epoch 971/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9435e-04 - val_loss: 3.2692e-04\n",
      "Epoch 972/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9304e-04 - val_loss: 3.6388e-04\n",
      "Epoch 973/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9118e-04 - val_loss: 3.4804e-04\n",
      "Epoch 974/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9568e-04 - val_loss: 3.4472e-04\n",
      "Epoch 975/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9253e-04 - val_loss: 3.6481e-04\n",
      "Epoch 976/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9207e-04 - val_loss: 3.5994e-04\n",
      "Epoch 977/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9069e-04 - val_loss: 3.5042e-04\n",
      "Epoch 978/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9606e-04 - val_loss: 3.3373e-04\n",
      "Epoch 979/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9787e-04 - val_loss: 3.3045e-04\n",
      "Epoch 980/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.8887e-04 - val_loss: 3.4416e-04\n",
      "Epoch 981/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9026e-04 - val_loss: 3.3502e-04\n",
      "Epoch 982/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9797e-04 - val_loss: 3.5434e-04\n",
      "Epoch 983/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9506e-04 - val_loss: 3.9623e-04\n",
      "Epoch 984/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9651e-04 - val_loss: 3.3166e-04\n",
      "Epoch 985/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9418e-04 - val_loss: 3.2787e-04\n",
      "Epoch 986/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.8972e-04 - val_loss: 3.4037e-04\n",
      "Epoch 987/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9708e-04 - val_loss: 3.4805e-04\n",
      "Epoch 988/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9020e-04 - val_loss: 3.3073e-04\n",
      "Epoch 989/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.8860e-04 - val_loss: 3.4688e-04\n",
      "Epoch 990/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9327e-04 - val_loss: 3.2992e-04\n",
      "Epoch 991/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.8899e-04 - val_loss: 3.6433e-04\n",
      "Epoch 992/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.8872e-04 - val_loss: 3.4041e-04\n",
      "Epoch 993/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9179e-04 - val_loss: 3.6993e-04\n",
      "Epoch 994/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9291e-04 - val_loss: 3.3414e-04\n",
      "Epoch 995/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.8405e-04 - val_loss: 3.3608e-04\n",
      "Epoch 996/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9770e-04 - val_loss: 3.3286e-04\n",
      "Epoch 997/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.8779e-04 - val_loss: 3.3958e-04\n",
      "Epoch 998/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.9209e-04 - val_loss: 3.4104e-04\n",
      "Epoch 999/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.8725e-04 - val_loss: 3.3119e-04\n",
      "Epoch 1000/1000\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 1.8843e-04 - val_loss: 3.3358e-04\n"
     ]
    }
   ],
   "source": [
    "'''Training to generate weights'''\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, verbose=0, mode='auto')\n",
    "#autoencoder_train = autoencoder.fit(train_X,train_ground, batch_size=batch_size,epochs=300,verbose=1,validation_data=(valid_X,valid_ground),callbacks=[callback_early_stopping])\n",
    "autoencoder_train = autoencoder.fit(train_X,train_ground, batch_size=batch_size,epochs=1000,verbose=1,validation_data=(valid_X,valid_ground))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vFE1Zq5czKaw"
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "Y_train=np.array(Y_train)-1\n",
    "Y_train = to_categorical(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iwx6RN1zzKa0"
   },
   "outputs": [],
   "source": [
    "train_X,valid_X,train_label,valid_label = train_test_split(X_train,Y_train,test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tf-odmqhzKa5"
   },
   "outputs": [],
   "source": [
    "def encoder(input_img):\n",
    "    #encoder\n",
    "    #input = 28 x 28 x 1 (wide and thin)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) #28 x 28 x 32\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 256 (small and thick)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    return conv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ctVuP2TwzKa8"
   },
   "outputs": [],
   "source": [
    "numclasses=3\n",
    "def fc(enco):\n",
    "    flat = Flatten()(enco)\n",
    "    den = Dense(128, activation='relu')(flat)\n",
    "    out = Dense(num_classes, activation='softmax')(den)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NvoVu4JAzKbC"
   },
   "outputs": [],
   "source": [
    "encode = encoder(input_img)\n",
    "full_model = Model(input_img,fc(encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s1p0TaUtzKbF"
   },
   "outputs": [],
   "source": [
    "for l1,l2 in zip(full_model.layers[:19],autoencoder.layers[0:19]):\n",
    "    l1.set_weights(l2.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "fOiNR6L6zKbL",
    "outputId": "9651b77e-a32f-4ec1-9eef-d38b4ceb15ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.11362907,  0.25356957, -0.11609847,  0.17133437,\n",
       "          0.21598338,  0.00907517, -0.03094127,  0.2315397 ,\n",
       "          0.180728  ,  0.014624  ,  0.02743706,  0.3285325 ,\n",
       "         -0.08050322,  0.18555117, -0.27073142, -0.23844512,\n",
       "          0.03366519, -0.27044278,  0.23921314, -0.03397636,\n",
       "          0.00746475, -0.08939018, -0.21742521,  0.06729656,\n",
       "         -0.13283393,  0.02616836,  0.02298508, -0.05252221,\n",
       "         -0.00270513,  0.24633063, -0.12611526,  0.06411856]],\n",
       "\n",
       "       [[-0.05995375, -0.13024835, -0.08822802,  0.28121138,\n",
       "          0.8695374 , -0.07333606,  0.05115486,  0.12083048,\n",
       "          0.08125699, -0.17007291, -0.22207038,  0.40457684,\n",
       "         -0.09516051,  0.08190954,  0.06898218, -0.10013296,\n",
       "          0.03262295, -0.32640663, -0.24349947,  0.19355413,\n",
       "          0.25741628,  0.1910985 ,  0.11805422, -0.04609126,\n",
       "          0.09000854, -0.20540766, -0.01685459, -0.2255084 ,\n",
       "          0.02688038, -0.17870867,  0.16697122,  0.17078279]],\n",
       "\n",
       "       [[-0.14409797,  0.09079653, -0.06023518,  0.10815424,\n",
       "          0.10086372,  0.08580353,  0.30910042, -0.1637568 ,\n",
       "          0.06016886, -0.26093012, -0.04346375, -0.06189138,\n",
       "          0.0428324 ,  0.20405704,  0.03833135, -0.1865398 ,\n",
       "          0.07002331,  0.06294829, -0.17284623, -0.1046124 ,\n",
       "          0.38043866,  0.1423127 , -0.1890706 ,  0.13992465,\n",
       "          0.20544721, -0.20463178,  0.03401706,  0.3548864 ,\n",
       "         -0.3450856 , -0.1616282 ,  0.24122654,  0.09761418]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Comparing to check that the weights are set correctly'''\n",
    "autoencoder.get_weights()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "-ldDAnkFzKbP",
    "outputId": "055ab2ac-0de1-4ca9-e796-1b09fdf60f31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.11362907,  0.25356957, -0.11609847,  0.17133437,\n",
       "          0.21598338,  0.00907517, -0.03094127,  0.2315397 ,\n",
       "          0.180728  ,  0.014624  ,  0.02743706,  0.3285325 ,\n",
       "         -0.08050322,  0.18555117, -0.27073142, -0.23844512,\n",
       "          0.03366519, -0.27044278,  0.23921314, -0.03397636,\n",
       "          0.00746475, -0.08939018, -0.21742521,  0.06729656,\n",
       "         -0.13283393,  0.02616836,  0.02298508, -0.05252221,\n",
       "         -0.00270513,  0.24633063, -0.12611526,  0.06411856]],\n",
       "\n",
       "       [[-0.05995375, -0.13024835, -0.08822802,  0.28121138,\n",
       "          0.8695374 , -0.07333606,  0.05115486,  0.12083048,\n",
       "          0.08125699, -0.17007291, -0.22207038,  0.40457684,\n",
       "         -0.09516051,  0.08190954,  0.06898218, -0.10013296,\n",
       "          0.03262295, -0.32640663, -0.24349947,  0.19355413,\n",
       "          0.25741628,  0.1910985 ,  0.11805422, -0.04609126,\n",
       "          0.09000854, -0.20540766, -0.01685459, -0.2255084 ,\n",
       "          0.02688038, -0.17870867,  0.16697122,  0.17078279]],\n",
       "\n",
       "       [[-0.14409797,  0.09079653, -0.06023518,  0.10815424,\n",
       "          0.10086372,  0.08580353,  0.30910042, -0.1637568 ,\n",
       "          0.06016886, -0.26093012, -0.04346375, -0.06189138,\n",
       "          0.0428324 ,  0.20405704,  0.03833135, -0.1865398 ,\n",
       "          0.07002331,  0.06294829, -0.17284623, -0.1046124 ,\n",
       "          0.38043866,  0.1423127 , -0.1890706 ,  0.13992465,\n",
       "          0.20544721, -0.20463178,  0.03401706,  0.3548864 ,\n",
       "         -0.3450856 , -0.1616282 ,  0.24122654,  0.09761418]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.get_weights()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vKbl5nijzKbX"
   },
   "outputs": [],
   "source": [
    "'''Using generate weigths from other models hence first 19 layers are not disabled'''\n",
    "for layer in full_model.layers[0:19]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5_CaunNMzKbe"
   },
   "outputs": [],
   "source": [
    "full_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QGIITnIYm68Y"
   },
   "outputs": [],
   "source": [
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1714
    },
    "colab_type": "code",
    "id": "F3MbEEfhzKbh",
    "outputId": "5bf34af8-84a8-4b9b-df11-f83553a5d247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1714 samples, validate on 572 samples\n",
      "Epoch 1/50\n",
      "1714/1714 [==============================] - 2s 1ms/step - loss: 9.7479 - acc: 0.3705 - val_loss: 9.2065 - val_acc: 0.4248\n",
      "Epoch 2/50\n",
      "1714/1714 [==============================] - 1s 387us/step - loss: 8.5748 - acc: 0.4632 - val_loss: 8.2473 - val_acc: 0.4878\n",
      "Epoch 3/50\n",
      "1714/1714 [==============================] - 1s 395us/step - loss: 5.8583 - acc: 0.6284 - val_loss: 4.8567 - val_acc: 0.6923\n",
      "Epoch 4/50\n",
      "1714/1714 [==============================] - 1s 398us/step - loss: 4.4226 - acc: 0.7200 - val_loss: 4.4882 - val_acc: 0.7150\n",
      "Epoch 5/50\n",
      "1714/1714 [==============================] - 1s 387us/step - loss: 4.0328 - acc: 0.7462 - val_loss: 4.2367 - val_acc: 0.7360\n",
      "Epoch 6/50\n",
      "1714/1714 [==============================] - 1s 391us/step - loss: 3.7866 - acc: 0.7614 - val_loss: 3.8753 - val_acc: 0.7517\n",
      "Epoch 7/50\n",
      "1714/1714 [==============================] - 1s 395us/step - loss: 3.6718 - acc: 0.7678 - val_loss: 4.1692 - val_acc: 0.7378\n",
      "Epoch 8/50\n",
      "1714/1714 [==============================] - 1s 387us/step - loss: 3.8938 - acc: 0.7538 - val_loss: 5.0387 - val_acc: 0.6748\n",
      "Epoch 9/50\n",
      "1714/1714 [==============================] - 1s 391us/step - loss: 3.8833 - acc: 0.7520 - val_loss: 3.7801 - val_acc: 0.7587\n",
      "Epoch 10/50\n",
      "1714/1714 [==============================] - 1s 388us/step - loss: 3.7268 - acc: 0.7649 - val_loss: 4.1129 - val_acc: 0.7448\n",
      "Epoch 11/50\n",
      "1714/1714 [==============================] - 1s 387us/step - loss: 3.5818 - acc: 0.7760 - val_loss: 3.7717 - val_acc: 0.7605\n",
      "Epoch 12/50\n",
      "1714/1714 [==============================] - 1s 391us/step - loss: 3.3114 - acc: 0.7923 - val_loss: 3.5212 - val_acc: 0.7762\n",
      "Epoch 13/50\n",
      "1714/1714 [==============================] - 1s 395us/step - loss: 3.1271 - acc: 0.8022 - val_loss: 3.5489 - val_acc: 0.7780\n",
      "Epoch 14/50\n",
      "1714/1714 [==============================] - 1s 389us/step - loss: 3.0974 - acc: 0.8034 - val_loss: 3.5170 - val_acc: 0.7780\n",
      "Epoch 15/50\n",
      "1714/1714 [==============================] - 1s 398us/step - loss: 3.1133 - acc: 0.8005 - val_loss: 3.6968 - val_acc: 0.7657\n",
      "Epoch 16/50\n",
      "1714/1714 [==============================] - 1s 399us/step - loss: 2.9021 - acc: 0.8133 - val_loss: 3.1575 - val_acc: 0.8024\n",
      "Epoch 17/50\n",
      "1714/1714 [==============================] - 1s 394us/step - loss: 3.0783 - acc: 0.8069 - val_loss: 3.6665 - val_acc: 0.7675\n",
      "Epoch 18/50\n",
      "1714/1714 [==============================] - 1s 393us/step - loss: 2.7903 - acc: 0.8244 - val_loss: 3.2339 - val_acc: 0.7937\n",
      "Epoch 19/50\n",
      "1714/1714 [==============================] - 1s 397us/step - loss: 2.7672 - acc: 0.8226 - val_loss: 3.3424 - val_acc: 0.7902\n",
      "Epoch 20/50\n",
      "1714/1714 [==============================] - 1s 399us/step - loss: 2.5345 - acc: 0.8384 - val_loss: 3.1073 - val_acc: 0.8007\n",
      "Epoch 21/50\n",
      "1714/1714 [==============================] - 1s 393us/step - loss: 2.4552 - acc: 0.8448 - val_loss: 3.1402 - val_acc: 0.7972\n",
      "Epoch 22/50\n",
      "1714/1714 [==============================] - 1s 393us/step - loss: 2.6079 - acc: 0.8331 - val_loss: 3.3976 - val_acc: 0.7815\n",
      "Epoch 23/50\n",
      "1714/1714 [==============================] - 1s 393us/step - loss: 2.6202 - acc: 0.8349 - val_loss: 3.8091 - val_acc: 0.7587\n",
      "Epoch 24/50\n",
      "1714/1714 [==============================] - 1s 401us/step - loss: 2.8509 - acc: 0.8180 - val_loss: 3.1048 - val_acc: 0.8024\n",
      "Epoch 25/50\n",
      "1714/1714 [==============================] - 1s 393us/step - loss: 3.1130 - acc: 0.7999 - val_loss: 3.1971 - val_acc: 0.7972\n",
      "Epoch 26/50\n",
      "1714/1714 [==============================] - 1s 403us/step - loss: 2.5224 - acc: 0.8401 - val_loss: 4.4966 - val_acc: 0.7168\n",
      "Epoch 27/50\n",
      "1714/1714 [==============================] - 1s 397us/step - loss: 2.5689 - acc: 0.8349 - val_loss: 3.3461 - val_acc: 0.7920\n",
      "Epoch 28/50\n",
      "1714/1714 [==============================] - 1s 400us/step - loss: 2.2822 - acc: 0.8541 - val_loss: 2.7560 - val_acc: 0.8199\n",
      "Epoch 29/50\n",
      "1714/1714 [==============================] - 1s 392us/step - loss: 1.8925 - acc: 0.8798 - val_loss: 2.9190 - val_acc: 0.8112\n",
      "Epoch 30/50\n",
      "1714/1714 [==============================] - 1s 393us/step - loss: 2.0284 - acc: 0.8699 - val_loss: 2.6751 - val_acc: 0.8287\n",
      "Epoch 31/50\n",
      "1714/1714 [==============================] - 1s 389us/step - loss: 1.7973 - acc: 0.8856 - val_loss: 2.5266 - val_acc: 0.8409\n",
      "Epoch 32/50\n",
      "1714/1714 [==============================] - 1s 393us/step - loss: 1.4798 - acc: 0.9055 - val_loss: 2.4189 - val_acc: 0.8427\n",
      "Epoch 33/50\n",
      "1714/1714 [==============================] - 1s 394us/step - loss: 1.5076 - acc: 0.9043 - val_loss: 2.2793 - val_acc: 0.8549\n",
      "Epoch 34/50\n",
      "1714/1714 [==============================] - 1s 393us/step - loss: 1.5190 - acc: 0.9026 - val_loss: 2.1051 - val_acc: 0.8601\n",
      "Epoch 35/50\n",
      "1714/1714 [==============================] - 1s 391us/step - loss: 1.3905 - acc: 0.9113 - val_loss: 2.1358 - val_acc: 0.8619\n",
      "Epoch 36/50\n",
      "1714/1714 [==============================] - 1s 394us/step - loss: 1.5172 - acc: 0.9026 - val_loss: 2.1468 - val_acc: 0.8654\n",
      "Epoch 37/50\n",
      "1714/1714 [==============================] - 1s 391us/step - loss: 1.5457 - acc: 0.8991 - val_loss: 2.0476 - val_acc: 0.8706\n",
      "Epoch 38/50\n",
      "1714/1714 [==============================] - 1s 388us/step - loss: 1.3416 - acc: 0.9137 - val_loss: 2.1504 - val_acc: 0.8566\n",
      "Epoch 39/50\n",
      "1714/1714 [==============================] - 1s 399us/step - loss: 1.3400 - acc: 0.9125 - val_loss: 2.1338 - val_acc: 0.8636\n",
      "Epoch 40/50\n",
      "1714/1714 [==============================] - 1s 390us/step - loss: 1.3166 - acc: 0.9166 - val_loss: 2.1619 - val_acc: 0.8584\n",
      "Epoch 41/50\n",
      "1714/1714 [==============================] - 1s 390us/step - loss: 1.2684 - acc: 0.9183 - val_loss: 2.3868 - val_acc: 0.8462\n",
      "Epoch 42/50\n",
      "1714/1714 [==============================] - 1s 394us/step - loss: 1.3320 - acc: 0.9148 - val_loss: 2.0847 - val_acc: 0.8654\n",
      "Epoch 43/50\n",
      "1714/1714 [==============================] - 1s 390us/step - loss: 1.1932 - acc: 0.9236 - val_loss: 2.2710 - val_acc: 0.8531\n",
      "Epoch 44/50\n",
      "1714/1714 [==============================] - 1s 393us/step - loss: 1.2677 - acc: 0.9177 - val_loss: 2.2277 - val_acc: 0.8566\n",
      "Epoch 45/50\n",
      "1714/1714 [==============================] - 1s 394us/step - loss: 1.1105 - acc: 0.9288 - val_loss: 2.0645 - val_acc: 0.8671\n",
      "Epoch 46/50\n",
      "1714/1714 [==============================] - 1s 391us/step - loss: 1.1992 - acc: 0.9230 - val_loss: 2.1092 - val_acc: 0.8671\n",
      "Epoch 47/50\n",
      "1714/1714 [==============================] - 1s 391us/step - loss: 1.1472 - acc: 0.9265 - val_loss: 2.1791 - val_acc: 0.8619\n",
      "Epoch 48/50\n",
      "1714/1714 [==============================] - 1s 395us/step - loss: 1.1452 - acc: 0.9265 - val_loss: 2.1605 - val_acc: 0.8601\n",
      "Epoch 49/50\n",
      "1714/1714 [==============================] - 1s 389us/step - loss: 1.1429 - acc: 0.9265 - val_loss: 2.3142 - val_acc: 0.8497\n",
      "Epoch 50/50\n",
      "1714/1714 [==============================] - 1s 394us/step - loss: 1.0807 - acc: 0.9323 - val_loss: 1.8785 - val_acc: 0.8811\n"
     ]
    }
   ],
   "source": [
    "#classify_train = full_model.fit(train_X, train_label, batch_size=64,epochs=300,verbose=1,validation_data=(valid_X, valid_label),callbacks=[callback_early_stopping])\n",
    "classify_train = full_model.fit(train_X, train_label, batch_size=64,epochs=50,verbose=1,validation_data=(valid_X, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_-mEvuWzKbl"
   },
   "outputs": [],
   "source": [
    "'''Resetting to true to use while predictions'''\n",
    "for layer in full_model.layers[0:19]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "id": "OlGy8LnazKbr",
    "outputId": "2db56dfa-ae4b-4f22-8f8b-c7bcfb673fd5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w8EB3TOgt0+PgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VNXZwPHfQ0BCAFlCEBBD0FrZ\n1wgoUlYtgoJYpCK4VhFf11rbUndBrFpKFWut6AtaiSDVV9y3Ci1aWyAgggiIC2AEZUd2SPK8f5yZ\nLDAzmX0yM8/385nPzNy599xzJ/DcM2cVVcUYY0zyq5HoDBhjjIkOC+jGGJMiLKAbY0yKsIBujDEp\nwgK6McakCAvoxhiTIiygmzIikiEie0UkN5r7JpKI/EhEot43V0QGicj6Cu/XikifYPYN41xPi8jt\n4R4fIN37ReSZaKdrEqdmojNgwicieyu8zQIOASWe99eqakEo6alqCVAv2vumA1U9LRrpiMjVwFhV\n7Vch7aujkbZJfRbQk5iqlgVUTwnwalX9h7/9RaSmqhbHI2/GmPizKpcU5vlJ/YKIzBaRPcBYETlD\nRP4rIrtEZLOITBORWp79a4qIikie5/0sz+dvicgeEfmPiLQOdV/P5+eKyOcisltEHhORf4vIFX7y\nHUwerxWRL0Rkp4hMq3Bshoj8SUS2i8hXwOAA388dIjLnqG2Pi8hUz+urRWS153q+9JSe/aVVJCL9\nPK+zROQ5T95WAd2P2vdOEfnKk+4qERnm2d4R+DPQx1Odta3Cd3tvhePHe659u4jME5HmwXw3VRGR\nEZ787BKR+SJyWoXPbheRTSLyg4isqXCtvURkmWf79yLyh2DPZ2JAVe2RAg9gPTDoqG33A4eB83E3\n7zrA6UBP3K+zk4HPgRs8+9cEFMjzvJ8FbAPygVrAC8CsMPZtCuwBhns+uxU4Alzh51qCyeMrQAMg\nD9jhvXbgBmAV0BLIBha6f+Y+z3MysBeoWyHtLUC+5/35nn0EGAAcADp5PhsErK+QVhHQz/N6CvBP\noBHQCvjsqH1HAc09f5NLPHk4wfPZ1cA/j8rnLOBez+tzPHnsAmQCfwHmB/Pd+Lj++4FnPK/bevIx\nwPM3uh1Y63ndHtgANPPs2xo42fN6CTDa87o+0DPR/xfS+WEl9NT3oaq+pqqlqnpAVZeo6iJVLVbV\nr4DpQN8Ax7+oqoWqegQowAWSUPc9D1iuqq94PvsTLvj7FGQef6+qu1V1PS54es81CviTqhap6nbg\nwQDn+Qr4FHejATgb2KmqhZ7PX1PVr9SZD7wP+Gz4PMoo4H5V3amqG3Cl7ornnauqmz1/k+dxN+P8\nINIFGAM8rarLVfUgMAHoKyItK+zj77sJ5GLgVVWd7/kbPYi7KfQEinE3j/aearuvPd8duBvzqSKS\nrap7VHVRkNdhYsACeur7puIbEWkjIm+IyHci8gMwEWgS4PjvKrzeT+CGUH/7tqiYD1VVXInWpyDz\nGNS5cCXLQJ4HRnteX+J5783HeSKySER2iMguXOk40Hfl1TxQHkTkChH5xFO1sQtoE2S64K6vLD1V\n/QHYCZxYYZ9Q/mb+0i3F/Y1OVNW1wK9wf4ctniq8Zp5drwTaAWtFZLGIDAnyOkwMWEBPfUd32XsS\nVyr9kaoeD9yNq1KIpc24KhAARESoHICOFkkeNwMnVXhfVbfKucAgETkRV1J/3pPHOsCLwO9x1SEN\ngXeDzMd3/vIgIicDTwDXAdmedNdUSLeqLpabcNU43vTq46p2vg0iX6GkWwP3N/sWQFVnqWpvXHVL\nBu57QVXXqurFuGq1PwIviUhmhHkxYbKAnn7qA7uBfSLSFrg2Dud8HegmIueLSE3gZiAnRnmcC9wi\nIieKSDbw20A7q+p3wIfAM8BaVV3n+ag2cBywFSgRkfOAgSHk4XYRaSiun/4NFT6rhwvaW3H3tmtw\nJXSv74GW3kZgH2YDvxCRTiJSGxdYP1BVv794QsjzMBHp5zn3r3HtHotEpK2I9Pec74DnUYq7gEtF\npImnRL/bc22lEebFhMkCevr5FXA57j/rk7jGy5hS1e+BnwNTge3AKcDHuH7z0c7jE7i67pW4BrsX\ngzjmeVwjZ1l1i6ruAn4JvIxrWByJuzEF4x7cL4X1wFvA3yqkuwJ4DFjs2ec0oGK983vAOuB7EalY\ndeI9/m1c1cfLnuNzcfXqEVHVVbjv/AnczWYwMMxTn14beBjX7vEd7hfBHZ5DhwCrxfWimgL8XFUP\nR5ofEx5x1ZnGxI+IZOB+4o9U1Q8SnR9jUoWV0E1ciMhgTxVEbeAuXO+IxQnOljEpxQK6iZezgK9w\nP+d/CoxQVX9VLsaYMFiVizHGpAgroRtjTIqI6+RcTZo00by8vHie0hhjkt7SpUu3qWqgrr5AEAFd\nRGbghm5vUdUOnm2NcV3J8nBds0ap6s6q0srLy6OwsLCq3YwxxlQgIlWNeAaCq3J5hmNnrJsAvK+q\np+L6/E4IKXfGGGOirsqArqoLcQMrKhoOPOt5/SxwQZTzZYwxJkThNoqeoKqbPa+/A07wt6OIjBOR\nQhEp3Lp1a5inM8YYU5WIG0VVVSXAmo2qOh03/Sn5+fnWR9KYODpy5AhFRUUcPHgw0VkxQcjMzKRl\ny5bUquVvKp/Awg3o34tIc1Xd7FktZUuY6RhjYqioqIj69euTl5eHm+TSVFeqyvbt2ykqKqJ169ZV\nH+BDuFUur+Im8sHz/EqY6VSpoADy8qBGDfdcENKyx8akt4MHD5KdnW3BPAmICNnZ2RH9mgqm2+Js\noB/QRESKcDPJPQjMFZFf4CbFHxV2DgIoKIBx42D/fvd+wwb3HmBMxPPLGZMeLJgnj0j/VlUGdFUd\n7eejYOeGDtsdd5QHc6/9+912C+jGGFNZtR76v3FjaNuNMdXL9u3b6dKlC126dKFZs2aceOKJZe8P\nHw5u2vQrr7yStWvXBtzn8ccfpyBK9bFnnXUWy5cvj0pa8RbXof+hys111Sy+thtjoq+gwP0C3rjR\n/T+bPDmyX8PZ2dllwfHee++lXr163HbbbZX2KVuxvobv8uXMmTOrPM/1118ffiZTSLUuoU+eDFlZ\nlbdlZbntxpjo8rZZbdgAquVtVrHoiPDFF1/Qrl07xowZQ/v27dm8eTPjxo0jPz+f9u3bM3HixLJ9\nvSXm4uJiGjZsyIQJE+jcuTNnnHEGW7a4DnZ33nknjzzySNn+EyZMoEePHpx22ml89NFHAOzbt4+f\n/exntGvXjpEjR5Kfn19lSXzWrFl07NiRDh06cPvttwNQXFzMpZdeWrZ92rRpAPzpT3+iXbt2dOrU\nibFjx0b9OwtGtS6he0sG0SwxGGN8i3eb1Zo1a/jb3/5Gfn4+AA8++CCNGzemuLiY/v37M3LkSNq1\na1fpmN27d9O3b18efPBBbr31VmbMmMGECcfOPKKqLF68mFdffZWJEyfy9ttv89hjj9GsWTNeeukl\nPvnkE7p16xYwf0VFRdx5550UFhbSoEEDBg0axOuvv05OTg7btm1j5cqVAOzatQuAhx9+mA0bNnDc\ncceVbYu3al1CB/cPaf16KC11zxbMjYmNeLdZnXLKKWXBHGD27Nl069aNbt26sXr1aj777LNjjqlT\npw7nnnsuAN27d2f9+vU+077wwguP2efDDz/k4osvBqBz5860b98+YP4WLVrEgAEDaNKkCbVq1eKS\nSy5h4cKF/OhHP2Lt2rXcdNNNvPPOOzRo0ACA9u3bM3bsWAoKCsIeGBSpah/QjTHx4a9tKlZtVnXr\n1i17vW7dOh599FHmz5/PihUrGDx4sM/+2Mcdd1zZ64yMDIqLi32mXbt27Sr3CVd2djYrVqygT58+\nPP7441x77bUAvPPOO4wfP54lS5bQo0cPSkpKonreYFhAN8YAiW2z+uGHH6hfvz7HH388mzdv5p13\n3on6OXr37s3cuXMBWLlypc9fABX17NmTBQsWsH37doqLi5kzZw59+/Zl69atqCoXXXQREydOZNmy\nZZSUlFBUVMSAAQN4+OGH2bZtG/uPrr+Kg2pdh26MiZ9Etll169aNdu3a0aZNG1q1akXv3r2jfo4b\nb7yRyy67jHbt2pU9vNUlvrRs2ZJJkybRr18/VJXzzz+foUOHsmzZMn7xi1+gqogIDz30EMXFxVxy\nySXs2bOH0tJSbrvtNurXrx/1a6hKXNcUzc/PV1vgwpj4Wb16NW3btk10NqqF4uJiiouLyczMZN26\ndZxzzjmsW7eOmjWrV7nW199MRJaqar6fQ8pUrysxxpgY2bt3LwMHDqS4uBhV5cknn6x2wTxSqXU1\nxhjjR8OGDVm6dGmisxFTSdEouns3rF6d6FwYY0z1lhQl9GHDYN8+sOp3Y4zxLylK6OecA0uXwhZb\nRsMYY/xKioA+eLB7jkHXVGOMSRlJEdC7doWmTeGttxKdE2NMKPr373/MIKFHHnmE6667LuBx9erV\nA2DTpk2MHDnS5z79+vWjqm7QjzzySKUBPkOGDInKPCv33nsvU6ZMiTidaEuKgF6jhiulv/suJGA0\nrTEmTKNHj2bOnDmVts2ZM4fRo/2tm1NZixYtePHFF8M+/9EB/c0336Rhw4Zhp1fdJUVABxfQt2+3\nhlFjksnIkSN54403yhazWL9+PZs2baJPnz5l/cK7detGx44deeWVY5cmXr9+PR06dADgwIEDXHzx\nxbRt25YRI0Zw4MCBsv2uu+66sql377nnHgCmTZvGpk2b6N+/P/379wcgLy+Pbdu2ATB16lQ6dOhA\nhw4dyqbeXb9+PW3btuWaa66hffv2nHPOOZXO48vy5cvp1asXnTp1YsSIEezcubPs/N7pdL2Tgv3r\nX/8qW+Cja9eu7NmzJ+zv1pek6OUCrmG0Rg1X7dKzZ6JzY0zyueUWiPZCPF26gCcW+tS4cWN69OjB\nW2+9xfDhw5kzZw6jRo1CRMjMzOTll1/m+OOPZ9u2bfTq1Ythw4b5XVfziSeeICsri9WrV7NixYpK\n099OnjyZxo0bU1JSwsCBA1mxYgU33XQTU6dOZcGCBTRp0qRSWkuXLmXmzJksWrQIVaVnz5707duX\nRo0asW7dOmbPns1TTz3FqFGjeOmllwLOb37ZZZfx2GOP0bdvX+6++27uu+8+HnnkER588EG+/vpr\nateuXVbNM2XKFB5//HF69+7N3r17yczMDOHbrlrSlNCzs6FHD6tHNybZVKx2qVjdoqrcfvvtdOrU\niUGDBvHtt9/y/fff+01n4cKFZYG1U6dOdOrUqeyzuXPn0q1bN7p27cqqVauqnHjrww8/ZMSIEdSt\nW5d69epx4YUX8sEHHwDQunVrunTpAgSeohfc/Oy7du2ib9++AFx++eUsXLiwLI9jxoxh1qxZZSNS\ne/fuza233sq0adPYtWtX1EeqJk0JHVy1y333wbZtcNQN1xhThUAl6VgaPnw4v/zlL1m2bBn79++n\ne/fuABQUFLB161aWLl1KrVq1yMvL8zllblW+/vprpkyZwpIlS2jUqBFXXHFFWOl4eafeBTf9blVV\nLv688cYbLFy4kNdee43JkyezcuVKJkyYwNChQ3nzzTfp3bs377zzDm3atAk7r0dLmhI6wLnnuqWx\n3n030TkxxgSrXr169O/fn6uuuqpSY+ju3btp2rQptWrVYsGCBWzwtYBwBT/5yU94/vnnAfj0009Z\nsWIF4KberVu3Lg0aNOD777/nrQo/4+vXr++znrpPnz7MmzeP/fv3s2/fPl5++WX69OkT8rU1aNCA\nRo0alZXun3vuOfr27UtpaSnffPMN/fv356GHHmL37t3s3buXL7/8ko4dO/Lb3/6W008/nTVr1oR8\nzkCSqoSen+9K5m+9BZdckujcGGOCNXr0aEaMGFGpx8uYMWM4//zz6dixI/n5+VWWVK+77jquvPJK\n2rZtS9u2bctK+p07d6Zr1660adOGk046qdLUu+PGjWPw4MG0aNGCBQsWlG3v1q0bV1xxBT169ADg\n6quvpmvXrgGrV/x59tlnGT9+PPv37+fkk09m5syZlJSUMHbsWHbv3o2qctNNN9GwYUPuuusuFixY\nQI0aNWjfvn3Z6kvRknTT544ZA++9B9995xpJjTH+2fS5ySeS6XOTLiSeey5s3eom3s/Lc0E9Ly82\nK5MbY0wySaoqF4Cf/hREYNIkOHLEbduwAcaNc69tEWljTLpKuhJ6Tg7UqlUezL3273dLZxljKotn\ntaqJTKR/q6QL6ACeQWfH2LgxvvkwprrLzMxk+/btFtSTgKqyffv2iAYbJV2VC0CzZq5R9Gi5ufHP\nizHVWcuWLSkqKmLr1q2JzooJQmZmJi1btgz7+KQM6A8/DJddVnlbVpZrKDXGlKtVqxatW7dOdDZM\nnCRllcull0KvXuXdFlu1gunTrUHUGJPekrKEDjB+PPz3v7BsmZsv3Rhj0l1SltDBdV8Em6zLGGO8\nkjagN2vmSuZvv53onBhjTPWQtAEd4Oyz4aOPju2Tbowx6SipA3purluSbseOROfEGGMSL6kDundO\ndOtia4wxEQZ0EfmliKwSkU9FZLaIRHc9pSrk5LhnzxKBxhiT1sIO6CJyInATkK+qHYAM4OJoZSwY\nVkI3xphykVa51ATqiEhNIAvYFHmWgmcldGOMKRd2QFfVb4EpwEZgM7BbVY9ZHE5ExolIoYgURns+\nCSuhG2NMuUiqXBoBw4HWQAugroiMPXo/VZ2uqvmqmp/jLVJHSa1a0KCBBXRjjIHIqlwGAV+r6lZV\nPQL8H3BmdLIVvJwcq3IxxhiILKBvBHqJSJaICDAQWB2dbAWvSRMroRtjDERWh74IeBFYBqz0pDU9\nSvkKmpXQjTHGiWi2RVW9B7gnSnkJS5MmsHRpInNgjDHVQ1KPFIXyErqtsGWMSXcpEdAPH4Y9exKd\nE2OMSaykD+jevuhWj26MSXdJH9C9Xdutp4sxJt0lfUC30aLGGOMkfUC3+VyMMcZJ+oBuJXRjjHGS\nPqDXrw/HHWcldGOMSfqALmLD/40xBlIgoIMN/zfGGEihgG4ldGNMukuJgN6kiZXQjTEmJQK6ldCN\nMSZFAnqTJrB7t5vTxRhj0lVKBHTv4KLt2xObD2OMSaSUCOg2uMgYY1IkoNvwf2OMSbGAbiV0Y0w6\nS4mAbnOiG2NMigT07Gz3bCV0Y0w6S4mAXrMmNGpkJXRjTHpLiYAONrjIGGNSJqDbjIvGmHSXMgHd\nZlw0xqS7lAroVkI3xqSzlAno3hkXVROdE2OMSYyUCeg5OVBc7CbpMsaYdJQyAd0GFxlj0l3KBHQb\n/m+MSXcpE9CthG6MSXcpE9CthG6MSXcpF9CthG6MSVcpE9CzsiAz00roxpj0lTIBXcQGFxlj0lvK\nBHQoH1xkjDHpKKUCupXQjTHpLKUCupXQjTHpLKKALiINReRFEVkjIqtF5IxoZSwcVkI3xqSzmhEe\n/yjwtqqOFJHjgKwo5ClsOTmwZw8cOgS1aycyJ8YYE39hl9BFpAHwE+B/AVT1sKruilbGwmGjRY0x\n6SySKpfWwFZgpoh8LCJPi0jdo3cSkXEiUigihVtjXB/iHVx0+ulQowbk5UFBQUxPaYwx1UYkAb0m\n0A14QlW7AvuACUfvpKrTVTVfVfNzvBE3Rj7+2D1v3uzmRd+wAcaNs6BujEkPkQT0IqBIVRd53r+I\nC/AJM2PGsdv274c77oh/XowxJt7CDuiq+h3wjYic5tk0EPgsKrkK06ZNvrdv3BjffBhjTCJE2svl\nRqDA08PlK+DKyLMUvtxc38E7Nzf+eTHGmHiLqB+6qi731I93UtULVHVntDIWjgceOHZbVhZMnhz/\nvBhjTLyl1EjRMWOgRQsXxEWgVSuYPt1tN8aYVBdplUu1c8opkJEBCxYkOifGGBNfKVVCBze4yIb/\nG2PSUcoF9JwcGylqjElPKRfQvTMulpYmOifGGBNfKRfQc3KgpAR2JXRWGWOMib+UC+g2QZcxJl2l\nXED3ThdjDaPGmHSTsgHdSujGmHSTcgHdW+ViJXRjTLpJ2YBuJXRjTLpJuYCeleUeVkI3xqSblAvo\nYIOLjDHpKSUDug3/N8ako5QM6Dk5iQ3ohw8n7tzGmPSVsgE9UVUuy5dD/fqwZElizm+MSV8pGdAT\nWeUyZ44rob/3XmLOb4xJXykZ0HNyYN8+OHAg/ueeN889L1oUeD9jjIm2lAzoieqLvmYNrF0LdevC\nf/8LqvE9vzEmvaVkQG/a1D2vWRPf8778snu++WbYsgU2bIjv+Y0x6S0lA3q/fpCbC+PHw+7d8Tvv\nvHnQowf87GfuvVW7GGPiKSUDeoMGMHu2KyFfe218qj6+/RYWL4YLLoCOHSEz01W7GGNMvKRkQAc4\n80yYNAleeAGefjr253v1Vfd8wQVQqxbk51sJ3RgTXykb0AF++1s4+2y46Sb49NPYnmvePPjxj6FN\nG/e+Z09YtswGGRlj4ielA3qNGvDcc9CwIYwa5boyxsKuXTB/viudi7htPXvCoUPwySexOacxxhwt\npQM6wAknwKxZrsfLTTfF5hxvvgnFxS6ge/Xq5Z6t2sUYEy8pH9ABBg6E22+HGTPg+eejn/68edCs\nmSuVe7VsCc2bW8OoMSZ+0iKgA9x7r6vjHjvWVYvk5UFBQeTpHjwIb70Fw4e7Kh4vEVdKtxJ6clm1\nyvWMKi5OdE6MCV3aBPQXXoCNG8u7MG7YAOPGRR7U58+HvXsrV7d49ewJX3xhc7Mnk2efhenTobAw\n0TkxJnRpE9DvuMOVpivav99tj8S8eW52xf79j/3MWwWzeHFk5zDx4/1bffBBYvNhTDjSJqBv3Oh7\neyTD80tK4JVXYMgQqF372M/z8101jFW7JIeSkvKS+YcfJjYvxoQjbQJ6bq7/z559Nrw0//tfN2fL\niBG+P69XDzp0sIbRZLFmjeva2rChC+ilpYnOkTGhSZuAPnmyWzy6ojp1XMC94gqYOjX0NOfNc6NC\nzz3X/z69ermf8RYcqj9vdcu118KOHfGf3M2YSKVNQB8zxjV2tWrleqC0agVPPeV+Yl90EfzqV/Dg\ng8Gnp+pmVxw4EI4/3v9+PXu6gUeffx75NZjYWrzY/S2vusq9t3p0k2zSJqCDC+rr17vS8vr17n3t\n2m4ir9GjXV/1f/wjuLQ++wy+/NJ375aKvA2jVo9e/S1ZAqefDqee6gakWT26STZpFdD9ychwpfW2\nbV2Q37w58P6HD8Ntt7njhg0LvG/btq7UZwG9ejt40E3T0KOH+wV31llWQjfJJ+KALiIZIvKxiLwe\njQwlQkEBtG/vSt1bt8KAAf4HlpSUwGWXwdtvw1//6kaDBlKjhiv1+WsYPXgQzjnHDXiyevbEWb7c\n/c1PP92979PH9YD65pvE5suYUESjhH4zsDoK6SREQYEbYOTtvqjqGsNGjjx2X1W44QY3SOmhh+Dq\nq4M7R69esGKF6/d+dHrjxrkFpQsK4P77I7sWE74lS9xzjx7uuU8f92zVLiaZRBTQRaQlMBSIw4zj\nsXHHHccGWnD9y995p/K2u+5ypfLf/MY9gtWzpyvZL11aefvUqW42yPvuc6X+e+6B114L/RpM5BYv\nhhYt4MQT3ftOnVy3U6t2MUlFVcN+AC8C3YF+wOt+9hkHFAKFubm5Wt2IqLqy8rGPJk1Ui4rcflOn\num1XX61aWuo/vVmzVFu1cum2auXef/+9O7Zhw/Ltv/61ao0aqiNHuvT271ft3l31+ONV16yJw4Wb\nSn78Y9XhwytvO+cc1Y4dE5MfYyoCCjWYmBzMTj4PhPOAv3he+w3oFR/du3eP/ZWHqFUr38G8RQvV\nunVV+/RRfeopt23kSNXiYv9pzZqlmpVVOZ2sLNXrrvN948jNVd27t/z4DRvcTaRNG9Xdu2N+6cZj\n507395g8ufL2iRPd323HjsTkyxivYAN6JFUuvYFhIrIemAMMEJFZEaSXEL4GHGVlwcMPu2qQDz6A\na65xa4QOHep6tvjjq/pm/37X/93XuqYlJVC3bvn73FyYOxfWrYPLL7dG0njxDvf31p979enj/m4f\nfRT/PBkTjrADuqr+TlVbqmoecDEwX1XHRi1nceJrwNH06e6zilMCHDwI118feHZGf/PFlJT43r5p\n07Hb+veHKVPcKNQHHgjuGkxkNz/vCNH8/Mrbe/RwI4GtHt0kC+uHju8BR/5K24FmZ/Q3X4y/Un1u\nrrtB5OW57o3eOdpvvtl1Y7z7bnjjjdCvJ918/TXk5LgFTMKxZImbK79hw8rbs7Kge3cL6CZ5RCWg\nq+o/VfW8aKRVXfgrbW/c6DsIg//qm3Hj3LwxR28fMqS8y6Rq+Rztzz8PTz4JXbrAz38e/OjVdKTq\nuo/u2AHTpvmu2qrK4sXHVrd49enjAv6BA5Hl05i4CKaiPVqP6tgo6o+/xtLsbN8Nn7NmueN89XLx\nbs/Ndft7t/s7R6tW7pjNm1U7d1atVUt17tzYXOfbb6v++9+xSTse/vpX95316eOeCwtDO76oyB33\n6KO+P3/lFff5v/4VeV6NCRex7uUSziOZArq/HivZ2YGDcCj8dZkUqRzwa9d22554InrXt2WL6qhR\n5TepH34I7rjPPlO96CLVTZuil5dwrV+vWq+e6qBBridKZqbrURSKl19238F//uP7823bfPeAMSae\nLKBHga/SdqAgHKpQfgXUqOGe778/cD/4qpSWqs6Z47pH1qqlOn68S/eBB4I7/uyz3f4XXRR+HqKh\ntNTlpW5d1a+/dtvGjFFt0MD16Q/W736nWrOm6oED/vdp31518OCIsmtMRCygx0hV1SShCPVXQN26\n7vnmm1VLSo5N7+BBV4XgLzht3qw6YoRLIz9fdeVKt33oUNXGjavu+/6Pf7hjO3Vyz6+9Fvo1R4t3\nbMBf/lK+bf58t+2554JPZ+BA1W7dAu9z7bVuwFegMQjGxJIF9BjxF4S9deXhpBfsrwBQ/eUv3fOQ\nIapXXeVKjp06uRJ3xf2aNnVB+8ILVW+5RfWee1zQrl1b9cEHVY8cKc/DkiXumEmT/OeztNSld9JJ\nrnqmfXvXJrBnT3jXHYmNG12A7dev8o2tpET15JPd9mCUlLgS/fjxgfebNct9Px9/HH6ejYmEBfQY\n8tfwGS2BfgWUlqr+/vfuJtJ7eYFVAAASkElEQVSihQuyw4a5oDRxoqtnnzRJ9ZprVH/6U9W2bctv\nQL16qa5e7fucw4a5qQl27fL9+dy5Lo2ZM937Dz8sv8HEU2mpu4llZal++eWxn99/v8vXF19Undaa\nNW7fGTMC77dhg9tv2rTw8mxMpCygJ7FgfgWEUo9eWuoCdaBjli1z57nvvmM/O3xY9dRTXam8YrXD\ntde6uv1Qe5ZEYubMwMG1qMjl6fbbq07rb39zaXmrngI56STXiGxMIlhAT3KBuj/G6tfBBRe4Koid\nOytv93YNfOWVytt37lRt1szVQVeswomVL75w+evTx3cbgteQIe7XS1V5uvFG1y4RTN34JZeoNm8e\nWYO0MeGygJ6Col1/f7Tly12ad99dvm3fPhfIevf2Hcy8VTFTp/pO89Ah1XnzVNetiyxvq1a5fDRu\nXHVaL73k8vT664H369lTtW/f4M7/l7+4NH1V8xgTaxbQU1A0e9j487OfuQZH7wyDDzzgzvHBB773\nLy11vWSysly/cK+1a90UwTk57vgGDVTffz+8PBUWup4/zZoFVz1y6JA774gRgfc57jjV224LLg9r\n12qVDcfGxIoF9BQUzT7w/qxY4dK8807V7dtdID7vvMDHrF/vAvqQIaqzZ6v27+/SyMhwvWxeeMHV\nv9esqfrMM6HlZ+FCd4Np1Sq0Uv6vfuXO9913vj8vLHR5DGUE7rnnut5DofRzNyYaLKCnoKpK6NGq\nXx81yo3AvOoql9aKFVUf88c/luendWtXsq84mnTnTtfnG1Tvuiu4uui331atU0f1tNNUv/kmtGv4\n7DN3rj/8wffn3iqUir8qqrJggTsmmiN2jQmGBfQUFKgOvarPQmlgXbWq/NfApZdWPr+/G8aRIy54\nvvuu/wbLQ4dUr7zSpXvJJW4glD8vveRGsnbu7FZ8CscZZ7jFQrw3j+JiNziqf//ykbe5ucHf+EpL\nVXv0UD3lFBtkZOLLAnqK8hdUQ51M7LrrAjewjh7t6pi9w+qj1SBbWlreV7xPH1eSXrjQje68/37X\nf/6cc1zAPeOMyFYLevppd57HH1f9n/9x1SW+vqNQruPFF90xf/97+PkyJlTBBnRx+8ZHfn6+FnqX\nhzFRVaOGC0/BysjwvfBGq1ZuTvg9e6CoCNq2ddvz8tz0vv72D9Xs2XDFFXD4cOXtOTlunvj8fLfQ\nR716oafttWcPNG8O+/a56YuHDoV//hO2bTt232Cvo6QE2rSBRo1g0SK3KIoxsSYiS1U1v8r9LKCn\nBn8BN1Qivlf/8XfD8Ld/MD75xM1FnpvrAmpu7rHzyUfqvfdg+3Y47zx3c4jGdTz5JIwfDwsWQL9+\nUc2uMT4FG9BtxaIU4W9xjexs3/uHuoqSv9WY/G0PRufObr3Wn/7UlXqjHcwBzj4bLr64vKQfjeu4\n7DJo2hQeeijy/BkTTRbQU4S/tVEffdT/Kkq+tvtbRWnIEN/7T54c2+uKNn83vlCuo04dt0zg22/D\nihXRzZ8xEQmmoj1aD2sUTYxQerkE6hoZ60nJoi2W0yfs2OGmDRg71vfnW7ao3nCDmxsn0DQFxgQD\n6+ViwhHu4KVEzD1TVX5iOU2CqptpMiOjcl/24mLXx71Ro/LvcswY12XTmHBZQDdhCWd6AX/Bs6qu\nkdXtOkK1YYMbjXrLLe79f/7jJioD1QEDXH9+bxfNQYOCX+bPmKNZQDdhCadk6y94ZmTEPqj6E49p\nElTdwKu6dVUvv9ylf+KJbom/iiNhZ8xw30XXrm7VKGNCFWxAt0ZRU4m/xtUxY/wfs3Gj7+2++rkH\n2j+aYtErx5df/9r1cy8ogN/8BtasgZ//vHL/9CuvhFdfhbVr4cwz4fPPo5sHY7wsoJtjjBnjBtmU\nlrrnQMEc/AfJQF0jQ+WrK2Wgz6LRmyUYHTvCG2/AypWuG6O/gVBDhrh+63v2QO/eblCSMVEXTDE+\nWg+rcklNsa5Dj/YcNuFeYzTS+vxzN3lZRoabjsDfbJDGVITVoZt4CrWXSygBMlADZzQbPwPlNZqN\nu1u3umCekeFmtbzvvsQstm2ShwV0U22FGiADNXBGq/EzUJ5i1WNmzRo3Xzy4xTuefDI+S/mZ5BNs\nQLc6dBN3d9wB+/dX3rZ/v9se6rQD0Wr8DJQnf424kTbunnYavPQS/PvfcMopcO210L49TJsGO3dG\nlrZJTxbQTdz5C4TeaQZCmXYgWo2fgYJ2rHvMnHkmfPABzJsHxx/vphVo0QIuvRQWLgxtFk2T3iyg\nm7gL1CvGVyn5zTf9d6UMp5tlKHnKzY1PjxkRGD4cliyBjz+Gq65yXR379nVTGP/xj7B7d/TOZ1JU\nMPUy0XpYHbpR9V9f7aueOhaDgULJUyKnMNi7V3XmTNUzz3T5adTILe2Xag2oGzeq/u534a9MlQ6w\nRlFTnYU6MVii8hSLY8JRWKg6dKj7PnJyVKdMSY3Fqj/6SPWEE9x1detm0yP4YwHdJJ14TKgVTYnI\n73/+o3r22VrWM+axxwKvzVqdPfOMW+bwlFPcdWRkuGtLxonMPv9cdcQI1Z49Vffti376FtBNUkqm\nKXoT+YviX/9S/clP3PlOO82ty5osiotVb7vN5X3gQNXt2932GTPctksuCTzl8LJlqt27uxta//5u\nANu0aarvvadaVFR5Hp1Y27HDTc5Ws6ab0wdUJ0yI/nksoBsTY/GaAMyf0lLVN99Uzctz5x0/XnXX\nrvicO1y7dqkOGeLye/31qocPV/78gQfcZ7feeuyxR46oTprkgmfz5m5CtF69VBs0qPz9n3yy6quv\nxvY6Dh9WffRR1caN3YLm11zjRv1eeaXL34oV0T2fBXRjYizRdf5ee/e6AFijhmqLFqovvxzccaWl\nqgcOqG7b5homv/kmtPN+/bXq0qWqX37pStlHD4o6csSVmBctcnn6859V27Z1Ae+JJ/zn6cYb3ff4\nhz+Ub1+zRrVHD7d99OjyUr33mE2bVN9/31XdtG3r9hs6VPWLL0K7pq1bVf/+dzeSt0MH1TZtXKP0\n0KFuZs2bblK96y7VH//YnWPQINVPPik/fts21SZNVM84I7oLm1hANybGwqlDj2WV0pIlqp07u3xc\neKHqO++4eupJk1THjVM991zVjh1VmzZ11QO+fmF07uwaXDdt8n2O3btVn3pKtXdv3zezevXcFMLN\nm7sbzNGfN22qOn9+4OsoKVEdNcrt/+yzriScmelKwy+8UPX3cPiwu4Z69VRr13YB2Fe9dkmJuynN\nm+eqTbzfnfc6Bg9WvegiVy3UrZv7JXT88e7zNm1UX3vNd/XOs8+6ff7616rzGqxgA7q4fUMnIicB\nfwNOABSYrqqPBjomPz9fCwsLwzqfMdVRQUH5aFJvn3V/feALCtxAqYp97bOywus378+RI67P+r33\nwqFD5dtzcuCkk6BlS2jWzM0KmZUFdeuWP//wA7zwgpsJskYNt8D2pZe6/vGLF8Mzz8CLL8KBA25R\n7yuucKNdd++GXbsqP4vAiSe6AVLe5xYtXD78zcJZ0aFDbkDZ/Pnu/dCh8NRT0Lx58N/Fpk1w220w\ne7YbdTxhghuB+9ln7rF6dfnfIjPTzYI5YIB7dO8OtWr5Tre42F1DxSmSK1KFgQNh2TI3nXKzZsHn\n2R8RWaqq+VXuF0FAbw40V9VlIlIfWApcoKqf+TvGArpJZ3l5bvTr0Vq1ctMUR9M338AXX5QH8czM\n4I9duxZmzXKP9etdcC8thQYN4OKL3fzuPXr4D2jR8sMP8D//4wLslVeGf75//hNuuAFWrXLvTzoJ\n2rWr/OjWLbTvqCqff+6mVr7wQndDiVTMA7qPE74C/FlV3/O3jwV0ky58ldwvvdT3MH4RFzCrm9JS\n+PBDeP116NoVLrgA6tRJdK7Cc+SIKy23auWmV4iHiRPhnnvgrbdg8ODI0oprQBeRPGAh0EFVfzjq\ns3HAOIDc3NzuG3wVUYxJIf6qVurUge3bj90/FiV0k3iHDkHnznD4MHz66bHTR4Qi2IAe8VwuIlIP\neAm45ehgDqCq01U1X1Xzc3JyIj2dMdWev5kbIT6rKJnqoXZtePJJ+PprmDQpPueMKKCLSC1cMC9Q\n1f+LTpaMSW7+Zm7cscP/RGKBltgzyatvX1f/P2WKW6Yw1mqGe6CICPC/wGpVnRq9LBmT3HJzfTd+\n5uaWzxBZ0dFVNN5pgyF6vV9M4vzhD66HT+vWsT9XJCX03sClwAARWe55DIlSvoxJWqFOtxtocQ2T\n/LKz4f77/S8gHk1hl9BV9UMgxh2XjEk+3lJ1sP3TY7Uikkk/YQd0Y4x/vqpW/AlURWNMKGzFImMS\nLB4rIoXLGmuTiwV0YxIs3GX0/AXbUINwoHR8rfFqQb0aC2bCl2g9bHIuY0Lna0IvfxODXXddaBOG\nBZpgrLrMJmniMDlXOGzovzGhCXXUaUYGlJQcu93faNRA88ts3JhcUxWksriNFDXGxI6/Lo2+gjn4\nDubggrOvqpVAPWz8NcpaY231ZQHdmGos1K6L/qambdzYd31448a+9/d2tfTXWBut+vtArEE2DMHU\ny0TrYXXoxoTGXz12dnZodejZ2aGl461zj1b9fagLeyTbguGxhq1YZEzyCxTY/AVJX9sDrX8aarD1\nd5PJyIjeTSOcBtlkWmA8VBbQjUkR0QhU0eyx4u/mEOrDey2+gr2/Y/zdgMIt0SfLTcACujGmTDSr\nMEItoQcKztEq7furUqqqRB+NXz+BtkeLBXRjTCXRCjqh1qEHCraBSvuhpBVqiV41eu0Tofb9D4cF\ndGNMzIRSUg138FIobQH+HoHq70NNy9+vBn/b/V1DOCygG2OqjUA3gFBKt6GWqgP9OvCXVjQf0Sq5\nBxvQrR+6MSbmxoxxI1VLS92zd56aUOex8dc3/tFHfaezY4fvdDZu9J9WdrbvY/z18Q+0Pe7z3AcT\n9aP1sBK6MSZSoVRjVNW7Jxr97P1tD1SvHyqsysUYk+6i3Z0xlO3R7CoabEC3ybmMMSmtoCD41aOi\nfV5fE6sFMzXy0YKdnMtWLDLGpLRQVo+K9nkhvjcTC+jGGBMj8b6ZWC8XY4xJERbQjTEmRVhAN8aY\nFGEB3RhjUoQFdGOMSRFx7YcuIlsBH0vSBqUJsC2K2UkWdt3pJV2vG9L32oO57laqmlNVQnEN6JEQ\nkcJgOtanGrvu9JKu1w3pe+3RvG6rcjHGmBRhAd0YY1JEMgX06YnOQILYdaeXdL1uSN9rj9p1J00d\nujHGmMCSqYRujDEmAAvoxhiTIpIioIvIYBFZKyJfiMiEROcnVkRkhohsEZFPK2xrLCLvicg6z3Oj\nROYxFkTkJBFZICKficgqEbnZsz2lr11EMkVksYh84rnu+zzbW4vIIs+/9xdE5LhE5zUWRCRDRD4W\nkdc971P+ukVkvYisFJHlIlLo2Ra1f+fVPqCLSAbwOHAu0A4YLSLtEpurmHkGGHzUtgnA+6p6KvC+\n532qKQZ+partgF7A9Z6/capf+yFggKp2BroAg0WkF/AQ8CdV/RGwE/hFAvMYSzcDqyu8T5fr7q+q\nXSr0PY/av/NqH9CBHsAXqvqVqh4G5gDDE5ynmFDVhcDRy9oOB571vH4WuCCumYoDVd2sqss8r/fg\n/pOfSIpfu2d1sb2et7U8DwUGAC96tqfcdQOISEtgKPC0572QBtftR9T+nSdDQD8R+KbC+yLPtnRx\ngqpu9rz+DjghkZmJNRHJA7oCi0iDa/dUOywHtgDvAV8Cu1S12LNLqv57fwT4DVDqeZ9Nely3Au+K\nyFIRGefZFrV/57ZiURJRVRWRlO1nKiL1gJeAW1T1B1doc1L12lW1BOgiIg2Bl4E2Cc5SzInIecAW\nVV0qIv0SnZ84O0tVvxWRpsB7IrKm4oeR/jtPhhL6t8BJFd639GxLF9+LSHMAz/OWBOcnJkSkFi6Y\nF6jq/3k2p8W1A6jqLmABcAbQUES8ha1U/PfeGxgmIutxVagDgEdJ/etGVb/1PG/B3cB7EMV/58kQ\n0JcAp3pawI8DLgZeTXCe4ulV4HLP68uBVxKYl5jw1J/+L7BaVadW+Cilr11Ecjwlc0SkDnA2rv1g\nATDSs1vKXbeq/k5VW6pqHu7/83xVHUOKX7eI1BWR+t7XwDnAp0Tx33lSjBQVkSG4OrcMYIaqTk5w\nlmJCRGYD/XDTaX4P3APMA+YCubiph0ep6tENp0lNRM4CPgBWUl6nejuuHj1lr11EOuEawTJwhau5\nqjpRRE7GlVwbAx8DY1X1UOJyGjueKpfbVPW8VL9uz/W97HlbE3heVSeLSDZR+neeFAHdGGNM1ZKh\nysUYY0wQLKAbY0yKsIBujDEpwgK6McakCAvoxhiTIiygG2NMirCAbowxKeL/AR9gq2wowhpsAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Plotting accuracy and loss'''\n",
    "accuracy = classify_train.history['acc']\n",
    "val_accuracy = classify_train.history['val_acc']\n",
    "loss = classify_train.history['loss']\n",
    "val_loss = classify_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "bWklA2mjzKbw",
    "outputId": "e586040e-f2c4-47f9-c7ed-6ea5139df479"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.878521731687622\n",
      "Test accuracy: 0.8811188823693282\n"
     ]
    }
   ],
   "source": [
    "'''Predictions and Evaluations'''\n",
    "test_eval = full_model.evaluate(valid_X,valid_label, verbose=0)\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3-TMu8q5zKb1",
    "outputId": "ee94e817-2439-4139-97ca-b9e654c685e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(572, 64, 64, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.array(valid_X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kNo62wmQzKb7"
   },
   "outputs": [],
   "source": [
    "predicted_classes = full_model.predict(valid_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6avg8EjhHAfI"
   },
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(np.round(predicted_classes),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q3NeI6jc1PZx"
   },
   "outputs": [],
   "source": [
    "valid_label = np.argmax(np.round(valid_label),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "id": "otTgezyp1a8F",
    "outputId": "e68f059a-2208-4f4a-a54a-79a7507a871a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 1, 2, 2, 1, 0, 2, 1, 1, 1, 2, 0, 1, 2, 1, 0, 1, 2, 2, 1,\n",
       "       1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 0, 2, 1, 2, 1, 2, 1, 0, 1, 1, 0, 1,\n",
       "       1, 2, 1, 0, 1, 1, 1, 2, 0, 2, 2, 1, 0, 0, 0, 1, 1, 0, 2, 0, 1, 1,\n",
       "       0, 1, 2, 2, 2, 2, 1, 1, 0, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 0,\n",
       "       0, 2, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 2, 0, 2, 2, 1,\n",
       "       2, 1, 1, 2, 2, 1, 0, 1, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0,\n",
       "       0, 1, 0, 1, 2, 1, 1, 2, 1, 2, 1, 0, 1, 0, 2, 0, 1, 2, 2, 1, 2, 1,\n",
       "       1, 2, 1, 1, 2, 1, 0, 0, 1, 2, 2, 1, 0, 1, 1, 0, 1, 1, 1, 0, 2, 2,\n",
       "       1, 2, 2, 1, 2, 0, 2, 2, 2, 0, 1, 2, 2, 1, 1, 0, 1, 2, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 2, 1, 2, 2, 0, 2, 0, 1, 1, 2, 0, 2, 1, 0,\n",
       "       1, 1, 2, 2, 1, 2, 0, 2, 2, 1, 0, 1, 0, 0, 1, 2, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 2, 0, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       1, 1, 2, 0, 1, 0, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 0, 1, 2, 2,\n",
       "       2, 1, 1, 0, 0, 0, 0, 2, 1, 1, 0, 1, 1, 1, 0, 2, 1, 2, 0, 2, 2, 1,\n",
       "       2, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1,\n",
       "       0, 1, 0, 1, 2, 1, 0, 2, 1, 1, 1, 0, 2, 1, 1, 0, 1, 1, 2, 2, 1, 1,\n",
       "       1, 2, 1, 0, 1, 0, 1, 1, 0, 2, 0, 1, 2, 1, 1, 0, 1, 1, 1, 0, 1, 2,\n",
       "       1, 1, 1, 1, 1, 0, 2, 2, 1, 2, 0, 0, 1, 0, 1, 1, 2, 1, 0, 1, 2, 1,\n",
       "       2, 2, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 2, 1,\n",
       "       2, 1, 2, 1, 1, 1, 1, 0, 2, 2, 0, 0, 1, 1, 1, 1, 1, 2, 2, 0, 2, 2,\n",
       "       2, 1, 2, 2, 2, 1, 2, 2, 1, 0, 1, 1, 1, 1, 0, 1, 1, 2, 1, 2, 2, 2,\n",
       "       0, 1, 1, 1, 2, 2, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 2, 0,\n",
       "       2, 1, 2, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 2, 2, 0, 2, 1, 0, 2,\n",
       "       1, 1, 0, 0, 1, 1, 0, 2, 2, 2, 2, 1, 0, 1, 2, 0, 1, 2, 1, 0, 1, 2,\n",
       "       1, 2, 2, 0, 1, 0, 2, 0, 0, 1, 1, 1, 1, 0, 2, 2, 2, 0, 1, 1, 1, 1,\n",
       "       2, 0, 2, 1, 1, 1, 2, 0, 1, 2, 0, 1, 1, 1, 0, 2, 1, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "1EsREORHzyhC",
    "outputId": "7a075c76-a37e-4133-ba45-de0554b7803d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.77      0.74      0.76       132\n",
      "     Class 1       0.90      0.90      0.90       279\n",
      "     Class 2       0.94      0.96      0.95       161\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       572\n",
      "   macro avg       0.87      0.87      0.87       572\n",
      "weighted avg       0.88      0.88      0.88       572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = [\"Class {}\".format(i) for i in range(3)]\n",
    "print(classification_report(valid_label, predicted_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "id": "iTB9mUFf0OHW",
    "outputId": "c0c46798-2021-40b2-8133-4958d0f6ece3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 1, 2, 2, 1,\n",
       "       1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 0, 2, 1, 2, 1, 2, 1, 0, 1, 1, 0, 1,\n",
       "       1, 2, 0, 0, 1, 1, 1, 2, 1, 2, 2, 1, 0, 0, 0, 1, 0, 0, 2, 1, 1, 1,\n",
       "       0, 1, 2, 2, 2, 2, 1, 1, 0, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 0,\n",
       "       0, 2, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 2, 0, 2, 2, 1,\n",
       "       2, 1, 0, 2, 0, 1, 0, 1, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 0, 2, 0, 1,\n",
       "       0, 1, 0, 1, 2, 1, 1, 2, 1, 2, 1, 0, 1, 0, 2, 0, 1, 2, 2, 1, 2, 1,\n",
       "       1, 2, 0, 1, 2, 1, 0, 0, 1, 2, 2, 1, 0, 1, 1, 0, 1, 1, 1, 0, 2, 2,\n",
       "       1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 0, 2, 1, 1, 1, 1, 2, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 1, 2, 0, 2, 2, 0, 2, 0, 0, 1, 2, 0, 2, 1, 0,\n",
       "       1, 1, 2, 2, 1, 2, 0, 2, 2, 1, 0, 1, 0, 0, 0, 2, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 2, 0, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 0, 2, 2, 2, 2,\n",
       "       1, 1, 2, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 1, 1, 2, 2,\n",
       "       2, 1, 1, 2, 0, 0, 0, 2, 1, 0, 2, 1, 1, 1, 0, 2, 1, 2, 0, 2, 2, 1,\n",
       "       2, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 2, 1, 1, 2, 1, 1, 2, 1, 1,\n",
       "       0, 0, 0, 1, 2, 0, 0, 2, 1, 1, 1, 1, 2, 1, 1, 0, 0, 1, 2, 2, 1, 1,\n",
       "       1, 2, 1, 0, 1, 0, 1, 1, 0, 2, 0, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 2,\n",
       "       1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 0, 1, 2, 1, 0, 1, 2, 1,\n",
       "       2, 2, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 2, 1,\n",
       "       2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 0, 0, 1, 1, 1, 1, 1, 2, 2, 0, 2, 2,\n",
       "       2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2,\n",
       "       0, 0, 1, 1, 2, 2, 1, 0, 1, 0, 1, 1, 0, 0, 1, 2, 1, 0, 1, 0, 2, 0,\n",
       "       2, 1, 2, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2, 0, 0, 2,\n",
       "       1, 2, 0, 0, 1, 1, 0, 2, 2, 1, 2, 1, 0, 1, 2, 2, 1, 2, 1, 1, 1, 0,\n",
       "       1, 2, 2, 0, 1, 0, 2, 0, 0, 0, 1, 1, 1, 0, 2, 1, 2, 2, 1, 1, 1, 1,\n",
       "       2, 0, 0, 1, 1, 1, 2, 1, 1, 2, 0, 1, 1, 1, 0, 2, 1, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "clGcRgbRJ3Yt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Project_autoencoder.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
