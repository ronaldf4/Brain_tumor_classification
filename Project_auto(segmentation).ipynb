{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\Ron\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from builtins import str\n",
    "\n",
    "from netrc import netrc\n",
    "\n",
    "import tensorflow as tf\n",
    "#!pip install tflearn\n",
    "\n",
    "import tflearn\n",
    "\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "\n",
    "from tflearn.layers.normalization import batch_normalization\n",
    "\n",
    "from tflearn.layers.conv import conv_2d, upsample_2d, max_pool_2d, avg_pool_2d, conv_3d, grouped_conv_2d, upsample_2d,max_pool_3d, conv_2d_transpose, atrous_conv_2d, upscore_layer, resnext_block\n",
    "\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "from tflearn.layers.recurrent import lstm\n",
    "\n",
    "from tflearn.layers.embedding_ops import embedding\n",
    "\n",
    "from tflearn.layers.merge_ops import merge\n",
    "\n",
    "\n",
    "\n",
    "from tflearn.objectives import softmax_categorical_crossentropy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Model:\n",
    "\n",
    "    # Building convolutional network\n",
    "\n",
    "\n",
    "\n",
    "    input_shape = None\n",
    "\n",
    "    output_shape = None\n",
    "\n",
    "    encoded_network = None\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self,input_shape,output_shape):\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "\n",
    "\n",
    "    def inception(self,network, filter_num,activation='relu', regularizer=None,strides=1,trainable=True):\n",
    "\n",
    "\n",
    "\n",
    "        network1 = conv_2d(network, int(filter_num/3), 1, activation='relu',strides=1,regularizer=regularizer,trainable=trainable)\n",
    "\n",
    "        network1 = conv_2d(network1, filter_num, 5, activation='relu',strides=strides,regularizer=regularizer,trainable=trainable)\n",
    "\n",
    "        network2 = conv_2d(network, int(filter_num/3), 1, activation='relu',strides=1,regularizer=regularizer,trainable=trainable)\n",
    "\n",
    "        network2 = conv_2d(network2, filter_num, 3, activation='relu',strides=strides,regularizer=regularizer,trainable=trainable)\n",
    "\n",
    "        network3 = conv_2d(network, int(filter_num/3), 1, activation='relu',strides=1,regularizer=regularizer,trainable=trainable)\n",
    "\n",
    "        network3 = conv_2d(network3, filter_num, 2, activation='relu',strides=strides,regularizer=regularizer,trainable=trainable)\n",
    "\n",
    "        # network4 = max_pool_2d(network, kernel_size=2, strides=strides)\n",
    "\n",
    "        # network5 = max_pool_2d(network, kernel_size=3, strides=strides)\n",
    "\n",
    "        # network6 = max_pool_2d(network, kernel_size=5, strides=strides)\n",
    "\n",
    "        network = merge([network1, network2, network3] , mode='concat', axis=3)\n",
    "\n",
    "\n",
    "\n",
    "        return network\n",
    "\n",
    "\n",
    "\n",
    "    def load_model(self):\n",
    "\n",
    "\n",
    "\n",
    "        network = input_data(shape=self.input_shape, name='input')\n",
    "\n",
    "\n",
    "\n",
    "        network = self.inception(network, 64)\n",
    "\n",
    "        network = conv_2d(network, 128, 3, activation='relu')\n",
    "\n",
    "        network = conv_2d(network, 128, 3, activation='relu')\n",
    "\n",
    "        network = self.inception(network,64,strides=2)\n",
    "\n",
    "\n",
    "\n",
    "        network = conv_2d(network, 128, 3, activation='relu')\n",
    "\n",
    "        network = conv_2d(network, 128, 3, activation='relu')\n",
    "\n",
    "        network = conv_2d(network, 128, 3, activation='relu',strides=2)\n",
    "\n",
    "        network = self.inception(network, 96)\n",
    "\n",
    "\n",
    "\n",
    "        network = conv_2d(network, 256, 3, activation='relu')\n",
    "\n",
    "        network = conv_2d(network, 256, 3, activation='relu')\n",
    "\n",
    "        network = conv_2d(network, 256, 3, activation='relu',strides=2)\n",
    "\n",
    "        network = self.inception(network, 96)\n",
    "\n",
    "\n",
    "\n",
    "        network = conv_2d(network, 256, 3, activation='relu')\n",
    "\n",
    "        network = conv_2d(network, 256, 3, activation='relu')\n",
    "\n",
    "        network = conv_2d(network, 256, 3, activation='relu', strides=2)\n",
    "\n",
    "        network = self.inception(network, 128)\n",
    "\n",
    "\n",
    "\n",
    "        network = conv_2d(network, 512, 3, activation='relu')\n",
    "\n",
    "        network = conv_2d(network, 512, 3, activation='relu')\n",
    "\n",
    "        network = conv_2d(network, 512, 3, activation='relu')\n",
    "\n",
    "        network = self.inception(network, 128)\n",
    "\n",
    "\n",
    "\n",
    "        network = fully_connected(network, 512, activation='relu')\n",
    "\n",
    "        network = dropout(network, 0.8)\n",
    "\n",
    "        network = fully_connected(network, 6192, activation='relu')\n",
    "\n",
    "        network = dropout(network, 0.8)\n",
    "\n",
    "        network = fully_connected(network, 4096, activation='relu')\n",
    "\n",
    "        network = dropout(network, 0.8)\n",
    "\n",
    "\n",
    "\n",
    "        network = fully_connected(network, self.output_shape, activation='relu')\n",
    "\n",
    "\n",
    "\n",
    "        return network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import csv\n",
    "\n",
    "import gc\n",
    "\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.python.training.training_util import global_step\n",
    "\n",
    "from tflearn import Momentum, Adam\n",
    "\n",
    "from tflearn.optimizers import Optimizer, RMSProp\n",
    "##################\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "import tflearn\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib.losses import log_loss, absolute_difference, mean_pairwise_squared_error\n",
    "\n",
    "from tflearn.metrics import accuracy_op\n",
    "\n",
    "from tflearn.objectives import softmax_categorical_crossentropy, categorical_crossentropy, mean_square,binary_crossentropy, roc_auc_score, hinge_loss\n",
    "\n",
    "import tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_pred, y_true):\n",
    "\n",
    "    error = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(y_pred, y_true))))\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "\n",
    "def accuracy_error(y_pred, y_true):\n",
    "\n",
    "    error = tf.sqrt(tf.subtract(y_pred, y_true))\n",
    "\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "os.chdir('C:\\\\Users\\\\Ron\\\\Desktop\\\\ML_proj\\\\Brain_cancer\\\\data')\n",
    "files=glob.glob('*.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import cv2 \n",
    "X=[]\n",
    "Y=[]\n",
    "data=[]\n",
    "count=0\n",
    "#a = 1\n",
    "for file in files:\n",
    "    with h5py.File(file,'r') as f:\n",
    "        variables=f.items()\n",
    "        for var in variables:\n",
    "            name= var[0]\n",
    "            data=var[1]\n",
    "            if (np.array(data['tumorMask']).shape[1] == 256):\n",
    "                count+=1\n",
    "                #print \n",
    "                (count)\n",
    "            else:\n",
    "                d=data['image']\n",
    "                X.append(cv2.resize(np.array(d),dsize=(64,64),interpolation=cv2.INTER_AREA))\n",
    "\n",
    "                #X.append(np.array(d))\n",
    "                #X.append(np.array(data['tumorMask']))\n",
    "                Y.append(data['label'][0][0])\n",
    "                \n",
    "                #a = data['label'][0][0]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler() #  scaling the data using minmax scaler for better performance\n",
    "# X= scaler.fit_transform(X)\n",
    "X=np.array(X).reshape(-1,64,64, 1)\n",
    "X = X.astype('float32')\n",
    "X = X / 255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2439, 64, 64, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
    "X_train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2439,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Y_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_height = X_train.shape[0]\n",
    "\n",
    "frame_width = X_train.shape[1]\n",
    "\n",
    "input_image = np.reshape(X_train, (-1, frame_height, frame_width, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_height = np.array(Y_train).shape[0]\n",
    "\n",
    "output_width = 1\n",
    "Y_train=np.array(Y_train)\n",
    "output_image = np.reshape(Y_train, (-1, output_height * output_width * 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ron\\Anaconda3\\lib\\site-packages\\tflearn\\initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From C:\\Users\\Ron\\Anaconda3\\lib\\site-packages\\tflearn\\layers\\core.py:239: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "Model = Model(input_shape=[None, frame_height, frame_width, 1], output_shape=output_height * output_width * 3)\n",
    "\n",
    "network = Model.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: 2UOZRY\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name Accuracy/ (raw) is illegal; using Accuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 51\n",
      "Validation samples: 13\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ron\\Anaconda3\\lib\\threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Ron\\Anaconda3\\lib\\threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Ron\\Anaconda3\\lib\\site-packages\\tflearn\\data_flow.py\", line 187, in fill_feed_dict_queue\n",
      "    data = self.retrieve_data(batch_ids)\n",
      "  File \"C:\\Users\\Ron\\Anaconda3\\lib\\site-packages\\tflearn\\data_flow.py\", line 222, in retrieve_data\n",
      "    utils.slice_array(self.feed_dict[key], batch_ids)\n",
      "  File \"C:\\Users\\Ron\\Anaconda3\\lib\\site-packages\\tflearn\\utils.py\", line 187, in slice_array\n",
      "    return X[start]\n",
      "IndexError: index 5 is out of bounds for axis 0 with size 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "momentum = Momentum(learning_rate=0.1, lr_decay=0.96, decay_step=100)\n",
    "\n",
    "adam = Adam(learning_rate= 0.1)\n",
    "\n",
    "rms = RMSProp(learning_rate=0.01, decay=0.9)\n",
    "\n",
    "\n",
    "\n",
    "net = tflearn.regression(network, optimizer=adam, shuffle_batches=True, metric='accuracy', batch_size=32,loss=mean_square)\n",
    "\n",
    "model = tflearn.DNN(net, tensorboard_verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "#model.load(X,weights_only=True)\n",
    "\n",
    "model.fit(input_image, output_image, n_epoch=10, show_metric=True,batch_size = 10, snapshot_step=len(input_image), validation_set=0.2,snapshot_epoch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
